Skill,Title,Company,Experience,Salary,Location,JD URL,Full JD,Job ID,Required Skills
Python,Python Developer - Data Scientist,Tiger Analytics,4-7 Yrs,Not disclosed,"Hyderabad, Chennai, Bengaluru",/job-listings-python-developer-data-scientist-tiger-analytics-hyderabad-chennai-bengaluru-4-to-7-years-290525024892,"MLOps and CI / CD Proficiency: Experience with MLOps practices and version control tools like Git to maintain CI / CD pipelines for efficient model deployment and managementBachelor s / Master s Degree in Engineering,Computer Science,or related fields. . Interest in core programming principles and an understanding of the importance of code structure.",290525024892,"Data Science,Data Structures,Numpy,Python,Pandas,SQL,Data,Science"
Python,Python Software Developer-N,Infosys,3-5 Yrs,Not disclosed,"Hyderabad, Pune, Bengaluru",/job-listings-python-software-developer-n-infosys-hyderabad-pune-bengaluru-3-to-5-years-230525027381,"Educational Requirements . MCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTechGood understanding of SDLC and agile methodologies",230525027381,"Django,Python,Flask,Software"
Python,Python Software Developer-AB-Pan India,Infosys,3-6 Yrs,Not disclosed,"Kolkata, Chennai, Bengaluru",/job-listings-python-software-developer-ab-pan-india-infosys-kolkata-chennai-bengaluru-3-to-6-years-300525033884,"MCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTech .Preferred Skills: Technology->OpenSystem->Python - OpenSystem->Python",300525033884,"Django,Python,Flask,Software"
Python,Python Software Developer-AB-Pan India-Bengaluru,Infosys,3-6 Yrs,4-9 Lacs PA,"Kolkata, Chennai, Bengaluru",/job-listings-python-software-developer-ab-pan-india-bengaluru-infosys-kolkata-chennai-bengaluru-3-to-6-years-300525032989,"MCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTechPreferred Skills: Technology->OpenSystem->Python - OpenSystem->Python",300525032989,"Django,Python,Flask,Software"
Python,Python Software Developer,IKS HEALTH,2-5 Yrs,Not disclosed,Remote,/job-listings-python-software-developer-iks-health-mumbai-all-areas-2-to-5-years-310525014478,"Deploy,monitor,and maintain services in cloud environments (preferably AWS,Azure,or GCP)Preferred candidate profile . 2-5 years of backend development experience using PythonProficient in working with SQL and NoSQL databases (e.g.,PostgreSQL,MySQL,MongoDB,Redis)Good working knowledge of React for UI collaboration or development",310525014478,"Python,Rest,Django,Microservices,Flask,Software development,Development,Software"
Python,Python Software Developer - PAN INDIA,Infosys,2-7 Yrs,Not disclosed,"Hyderabad, Chennai, Bengaluru",/job-listings-python-software-developer-pan-india-infosys-hyderabad-chennai-bengaluru-2-to-7-years-020425008271,Hiring for Python Developer with experience range 2 years & aboveMandatory Skills: PythonEducation: BE/B.Tech/MCA/M.Tech/MSc./MSInterview Mode-F2F,020425008271,"Python Development,Python,Python Framework,Django,Software development,Framework,Pan,Software"
Python,Data engineer - Python ETL Developer,HARMAN,3-5 Yrs,Not disclosed,Bengaluru,/job-listings-data-engineer-python-etl-developer-harman-international-bengaluru-3-to-5-years-300525503704,Data Visualization: Proficient in Excel and data visualization toolsEngineer audio systems and integrated technology platforms that augment the driving experience .,300525503704,"Infotainment,Automation,Data analysis,Image processing,Agile,German,Troubleshooting,Automotive"
Python,Python Software Developer,Xoriant,3-6 Yrs,Not disclosed,Hybrid - Pune,/job-listings-python-software-developer-xoriant-pune-3-to-6-years-220425010711,"Experience with REST API development and integration. Hands-on experience with Splunk (search,dashboards,alerts).",220425010711,"Automation Tools,Restfull Api,Splunk,Python,Windows plugin,Pandas,Flask,Software development"
Python,"Full Stack Python Developer (Cloud, IoT, Blockchain & Agile Expertise)",Synechron,5-10 Yrs,Not disclosed,Pune,/job-listings-full-stack-python-developer-cloud-iot-blockchain-agile-expertise-synechron-technologies-pvt-ltd-pune-5-to-10-years-290525915493,"Qualifications: . Bachelors or Masters degree in Computer Science,Software Engineering,or related fieldRelevant certifications in Python,cloud platforms,or full-stack development (preferred)Essential: Python (proficient),JavaScript (proficient)Preferred: Node.js,TypeScript .Front-end: React,Angular,Vue.js (preferred)Experience Requirements: .",290525915493,"Python,Agile Expertise,Cloud,Blockchain,Full Stack Python Developer,IoT,Stack,Agile"
Python,Python Developer,Enterprise Minds,0-1 Yrs,Not disclosed,Bengaluru,/job-listings-python-developer-enterpriseminds-india-private-limited-bengaluru-0-to-1-years-300525931376,"Bachelor s degree in Computer Science,Engineering,or a related fieldRequired QualificationsPreferred SkillsExperience Level: 3 5 Years. Employment Type: Full-Time. Role OverviewThe ideal candidate will have experience in building and optimizing data pipelines,ensuring efficient data processing and integration. . Key Responsibilities",300525931376,"data manipulation,python development,numpy,sql,pandas,python,microsoft azure,machine learning"
Python,"Software Developer (Python, PySpark, AWS)",Sopra Steria,3-8 Yrs,Not disclosed,Bengaluru,/job-listings-software-developer-python-pyspark-aws-sopra-steria-bengaluru-3-to-8-years-300525500910,"Practice and demonstrate Airbus Values . Well versed with developing,testing,documenting,publishing,maintaining and operating reliable and secure web applicationsMust to Have Skills:-Experience with Foundry (Slate,Workbook etc.)",300525500910,"Computer science,Prototype,Publishing,GIT,Data modeling,test driven development,Unit testing,Information technology"
Python,Python Software Developer / Data Engineer,CGI,5-7 Yrs,Not disclosed,Hybrid - Bengaluru,/job-listings-python-software-developer-data-engineer-cgi-bengaluru-5-to-7-years-190525013270,"Preferred candidate profile .Overall 5-7 years of Software Development Experience in python in delivery of IT Projects and specifically in the area of Data Systems / BISolution Architecture experience in the areas of Data Analytics,Integration and reporting (Specifically implementations using Open Source Tools (Python) / Big Data Distribution,Experience: 5 Years",190525013270,"RDBMS,Pandas,Oracle,Python,SQL,Numpy,Software,Data"
Python,"Software Developer, C++, Python, Linux",IBM,3-6 Yrs,Not disclosed,Pune,/job-listings-software-developer-c-python-linux-ibm-india-pvt-limited-pune-3-to-6-years-290525924852,"Bachelors Degree .Required educationPreferred educationRequired technical and professional expertise . 5+ years of extensive experience in C++,Perl,and Python,specializing in developing enterprise-grade backend systemsPreferred technical and professional experience .Proven experience with multi-threading,socket programming,and LDAP directory services",290525924852,"gdb,database design,postgresql,debugging,shell scripting,schema,kubernetes,python"
Python,Lead Software Engineer/Sr Software Engineer- Data Engineer - Python,CGI,N/A,Not disclosed,Hyderabad,/job-listings-lead-software-engineer-sr-software-engineer-data-engineer-python-cgi-information-systems-and-management-consultants-private-limited-hyderabad-6-to-8-years-300525931767,"Bachelors or Masters degree in Computer Science,Information Systems,or a related field.Required qualifications to be successful in this role: Minimum 6 years of experience as a Data Engineer or similar roleKnowledge of cloud services (AWS,GCP,or Azure) is preferredPreferred Skills: Experience with containerization (Docker,Kubernetes)",300525931767,"Data Engineering,Azure,Docker,GCP,HDFS,Python Spark,MongoDB,HFDS"
Python,Cybage Software is hiring Sr. Python Developers,Cybage,6-11 Yrs,Not disclosed,Pune,/job-listings-cybage-software-is-hiring-sr-python-developers-cybage-pune-6-to-11-years-250425005084,"Minimum 7 years of work experience using advanced Python Programming language & microservicesWell versed with developing REST APIs and Services using at least one Python web framework (Django,Flask,FastAPI)Good knowledge of version controls like Git,Github & SVNGood to have knowledge of Devops tools (like Docker & GKE) and third-party tools like Airflow,Elastic Search,etc",250425005084,"Python Developer,Python,Django Rest Api,Django,Rest Api Development,Django Framework,API,Python Development"
Python,Senior Data Engineer - Python,Relanto Global,4-9 Yrs,5-15 Lacs PA,"Hyderabad, Pune, Bengaluru",/job-listings-senior-data-engineer-python-relanto-global-hyderabad-pune-bengaluru-4-to-9-years-300525019366,". Bachelors or master s degree in computer science,Information Technology,Data Science,or a related fieldExperience with databases such as MongoDB,Elasticsearch,and MySQLMust have minimum 4 years of relevant experienceProficient in Python with hands-on experience building ETL pipelines for data extraction,transformation,and validation",300525019366,"python,Elastic,Data engineer,SQL,MongoDB,ETL,Data Engineering,Senior"
Python,Senior Python Developer,MSCI Services,3-6 Yrs,Not disclosed,Pune,/job-listings-senior-python-developer-msci-services-pune-3-to-6-years-280525030583,"MSCI,Pride & Allies,Women in Tech,and Women s Leadership Forum. At MSCI we are passionate about what we do,and we are inspired by our purpose to power better investment decisionsThe candidate should have excellent problem solving and debugging skills.Please note,this e-mail is intended only for individuals who are requesting a reasonable workplace accommodation",280525030583,"algorithms,enterprise software,data,software design,interpersonal skills,pyspark,research,sql"
Python,"Senior Developer (Python, Java, and IBM DataStage)",Synechron,6-11 Yrs,Not disclosed,Pune,/job-listings-senior-developer-python-java-and-ibm-datastage-synechron-technologies-pvt-ltd-pune-6-to-11-years-270525928942,"**Job Summary**Synechron is seeking an experienced Lead Python with Java Developer to join our team. This critical role is designed to drive the development and integration of robust software solutions that bolster our business objectives. The successful candidate will leverage their expertise in Python, Java, and data management technologies to deliver high-quality applications and contribute to strategic projects within the organization.**Software Requirements*****Required:*** Proficiency in Python and Java* Experience with ETL tools, specifically IBM DataStage***Preferred:*** Familiarity with SQL, BigData, PySpark, and Hive**Overall Responsibilities*** Lead the design, development, and maintenance of scalable software applications using Python and Java.* Oversee the integration of ETL processes using IBM DataStage.* Collaborate with cross-functional teams to define software requirements and deliver solutions that meet business needs.* Ensure the performance, quality, and responsiveness of applications through rigorous testing and optimization.* Mentor and guide junior developers, setting best practices and coding standards.**Technical Skills (By Category)*****Programming Languages:*****Required:** Python, Java***Databases/Data Management:*****Preferred:** SQL, BigData, Hive***Frameworks and Libraries:*****Preferred:** PySpark***Development Tools and Methodologies:*****Required:** IBM DataStage***Security Protocols:*****Preferred:** Understanding of data security measures in application development**Experience Requirements*** Minimum 6+ years of experience in software development roles.* Proven experience in developing applications using Python and Java.* Experience in the financial services industry is preferred but not mandatory.* Alternative pathways include significant project-based experience in software development and data management.**Day-to-Day Activities*** Develop and maintain high-quality, testable code in Python and Java.* Conduct regular code reviews and ensure adherence to best practices.* Collaborate with stakeholders to gather requirements and define project scope.* Participate in regular team meetings and contribute to project planning sessions.* Provide technical leadership and decision-making for software development projects.**Qualifications*** RequiredBachelor’s degree in Computer Science, Information Technology, or a related field.* PreferredCertifications in relevant programming languages or ETL tools.* Commitment to continuous professional development and staying current with industry trends.**Professional Competencies*** Strong critical thinking and problem-solving capabilities.* Demonstrated leadership and teamwork abilities.* Excellent communication and stakeholder management skills.* Adaptability and a continuous learning orientation.* Innovative mindset and ability to manage time and priorities effectively.__",270525928942,"python,data management,java,stakeholder management,protocols,hive,software development,technical leadership"
Python,"Full Stack Python Developer (Cloud, Mobile, IoT & Agile Expertise)",Synechron,5-10 Yrs,Not disclosed,Pune,/job-listings-full-stack-python-developer-cloud-mobile-iot-agile-expertise-synechron-technologies-pvt-ltd-pune-5-to-10-years-270525928974,"Cloud Technologies: Hands-on experience deploying and managing applications on AWS,Azure,or GCPProven experience developing scalable web and mobile applications using modern frameworks and architecturesBachelor s or Master s degree in Computer Science,Information Technology,or a related fieldPreferred: Node.js,TypeScript",270525928974,"python,backend development,relational databases,javascript,javascript frameworks,continuous integration,kubernetes,software development"
Python,Senior Python Developer (Django/Flask),Synechron,5-9 Yrs,Not disclosed,Pune,/job-listings-senior-python-developer-django-flask-synechron-technologies-pvt-ltd-pune-5-to-9-years-270525928911,"Bachelor s degree in Computer Science,Information Technology,or related field (or equivalent experience)ORM (Object-Relational Mapping)Proficient knowledge .Experience Requirements .Minimum of 7 years of experience in software development,specifically with PythonPythonAdvanced level,with experience in software development",270525928911,"agile methodology,software development,orm,flask,python framework,css,data management,dbms"
Python,"Analyst-Data Analytics (Python, SQL)",AMERICAN EXPRESS,0-4 Yrs,Not disclosed,Gurugram,/job-listings-analyst-data-analytics-python-sql-american-express-india-gurugram-0-to-4-years-300525501680,. Strong programming skills are preferredWillingness to challenge the status quoExperience with Big Data programming is a plus,300525501680,"Computer science,Career development,Automation,Finance,Programming,Wellness,Data analytics,Customer engagement"
Python,Python Software Developer- Pune (Pan India Infosys),Infosys,2-7 Yrs,Not disclosed,"Hybrid - Hyderabad, Chennai, Bengaluru",/job-listings-python-software-developer-pune-pan-india-infosys-infosys-hyderabad-chennai-bengaluru-2-to-7-years-210325022858,"Exciting Python developer Job Opportunity at Infosys!We are looking for skilled Python Developer to join our dynamic team **PAN INDIA.** If you have a passion for technology and a minimum of 2 years to 6 years of hands-on experience in python application development, this is your chance to make an impact.At Infosys, we value innovation, collaboration, and diversity. We believe that a diverse workforce drives creativity and fosters a richer company culture. Therefore, we strongly encourage applications from all genders and backgrounds.Ready to take your career to the next level? Join us in shaping the future of technology. Visit our careers page for more details on how to apply.",210325022858,"Python,Django,Flask,Software development,Pan,Software,Development"
Python,Software Engineer III Python React Devops,JPMorgan Chase Bank,0-6 Yrs,Not disclosed,Hyderabad,/job-listings-software-engineer-iii-python-react-devops-jp-morgan-chase-hyderabad-0-to-6-years-300525500095,"Formal training or certification on software engineering and site reliability concepts and 3+ years applied experience. . Proficient in at least one programming language such as Python,Reactjs and SALT.Experience in developing,debugging,and maintaining code in a large corporate environment with one or more modern programming languages and database querying languages.",300525500095,"System architecture,orchestration,Coding,Artificial Intelligence,Debugging,Agile,splunk,Troubleshooting"
Python,Python Developer - Pan India,Infosys,3-8 Yrs,Not disclosed,"Hyderabad, Chennai, Bengaluru",/job-listings-python-developer-pan-india-infosys-hyderabad-chennai-bengaluru-3-to-8-years-050325025072,Hiring for Python Developer with experience range 2 years & aboveMandatory Skills: PythonEducation: BE/B.Tech/MCA/M.Tech/MSc./MSInterview Mode-F2F,050325025072,"Python Framework,Python Development,Django,Pan,Python,Framework,Development"
Python,Python Developer - PAN INDIA,Infosys,3-8 Yrs,Not disclosed,"Hyderabad, Chennai, Bengaluru",/job-listings-python-developer-pan-india-infosys-hyderabad-chennai-bengaluru-3-to-8-years-130525025015,Hiring for Python Developer with experience range 2 years & aboveMandatory Skills: PythonEducation: BE/B.Tech/MCA/M.Tech/MSc./MSInterview Mode-F2F,130525025015,"Python Development,Python,Django,Pan,Development"
Python,Python Software Developer,Hexaware Technologies,4-9 Yrs,Not disclosed,"Hybrid - Pune, Chennai, Mumbai (All Areas)",/job-listings-python-software-developer-hexaware-technologies-pune-chennai-mumbai-all-areas-4-to-9-years-130225014528,"Candidate should have a deep understanding of Python framework,RESTful principles,and modern software development practicesStrong proficiency in Python and experience with framework like Flask,Django,or FastAPI.Experience with database integration (SQL / NoSQL).",130225014528,"Python,Django,Tornado,FastAPI,Rest Api Services,Flask,SQL,Software development"
Python,Python Software Developer,Shyena Tech Yarns,2-4 Yrs,Not disclosed,"Pune, Bengaluru",/job-listings-python-software-developer-shyena-tech-yarns-pune-bengaluru-2-to-4-years-290525036760,"Hands on experience in developing using AWS Services for now target S2,Redshift,Athena,Glue,Lambda etcGood problem solving and troubleshooting skillsSkills: Python + Flask+Fast API. Must HaveThorough Python web development experience",290525036760,"API,Python,Django,Numpy,Scikit-Learn,Flask,Software,Software development"
Python,Senior Data Engineer/Python Developer,Luxoft,7-12 Yrs,Not disclosed,Bengaluru,/job-listings-senior-data-engineer-python-developer-luxoft-india-llp-bengaluru-7-to-12-years-190525913281,"EducationTypically,a Bachelors degree in Computer Science (preferably MSc in Computer Science),Software Engineering,or a related field is requiredHands on experience working with APIs . Kafka / Azure EventHub streaming hands on experience .",190525913281,"sql,python,airflow,microsoft azure,data bricks,redis,unix scripting,apache"
Python,"Software Developer: C++, Python, Linux",IBM,3-6 Yrs,Not disclosed,Pune,/job-listings-software-developer-c-python-linux-ibm-india-pvt-limited-pune-3-to-6-years-230525922565,"Bachelors Degree .Required educationPreferred educationRequired technical and professional expertise . 5 + years of extensive experience in C++,Perl,and Python,specializing in developing enterprise-grade backend systemsPreferred technical and professional experience .Proven experience with multi-threading,socket programming,and LDAP directory services",230525922565,"gdb,database design,postgresql,debugging,shell scripting,schema,kubernetes,python"
Python,Senior Python Developer - With AI/ML,BMC Software,8-13 Yrs,Not disclosed,Hybrid - Pune,/job-listings-senior-python-developer-with-ai-ml-bmc-software-india-pvt-ltd-pune-8-to-13-years-270525938404,"BMC is looking for a talented Java Product Developer to join our family working on complex and distributed software, developing, and debugging software products, implementing features, and assisting the firm in assuring product quality.__**_Here is how, through this exciting role, YOU will contribute to BMC's and your own success:_**Contribute to be a member of the Development team responsible for developing and debugging of software products.Work on complex problems where analysis of situations or data requires an in-depth evaluation of several factors.Work across product lines with interaction of other BMC productsIndependently design and implement features that address customer needs with a sense of ownership within given timelinesAs every BMC employee, you will be given the opportunity to learn, be included in global projects, challenge yourself and be the innovator when it comes to solving everyday problems.**_To ensure youre set up for success, you will bring the following skillset & experience:_*** Design and develop platform solution based on best practices and web standards.* Participate in all aspects of product development, from requirements analysis to product release.* Lead features and participate in architecture and design reviews.* Design enterprise platform using agile methodology. This includes creating detailed design using UML, process flows, sequence diagrams, and pseudo-code level details ensuring solution alignment.* You have strong diagnostics, debugging, and troubleshooting skills.* Ability to work flexible hours and stay up to date with competing technologies and passionate about adapting technology to provide business-benefiting solutions balancing with platform limitations.* Provides complete documentation in the form of commented code, problem status information, and design documents.* Work on complex problems where analysis of situations or data requires an in-depth evaluation of several factors.* Self-learner, flexible and able to work in a multi-tasked and dynamic environment.* Excellent communication skills: demonstrated ability to explain complex technical concepts to both technical and non-technical audiences.**To ensure youre set up for success, you will bring the following skillset & experience**: You have 8+ years of experience with application development using Python, Java, RESTful services, high-performance, and multi-threading.* Familiarization with DevOps tools and concepts such as Infrastructure as code, Jenkins, Ansible, and Terraform.* You have experience in a Web based environment utilizing React, Angular, server-side rendering, HTML, CSS, JavaScript and TypeScript.* You have knowledge and experience with build tools such as Gradle and Maven.* Familiarity with cloud platforms (e.g., OCP, AWS, Azure, GCP).* You are familiar with modern version control system such as Git.* Strong knowledge of statistical analysis, data mining, and machine learning techniques.* Experience with machine learning frameworks and libraries (e.g., scikit-learn, TensorFlow, PyTorch).* Knowledge of SQL for data manipulation* Great communication skills, ability to explain predictive analytics to non-technical audience.* Proficiency in data exploration techniques and toolsWhilst these are nice to have, our team can help you develop in the following skills which are good to have :CI/CD (Jenkins) environment with popular DevOps toolsExperience with Agile methodology, use of Atlassian products Jira, Confluence )CA-DNP",270525938404,"Python,TypeScript,Azure,CSS,GCP,JavaScript,HTML,OCP"
Python,"DE&A - Core - Data Engineer (Snowflake, Python, AWS) DE&A - Core",Zensar,5-8 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-de-a-core-data-engineer-snowflake-python-aws-de-a-core-zensar-technologies-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-5-to-8-years-270525501411,"Experience with AWS services like S3,Lambda,Glue,Redshift,and Step Functions . . Hands-on experience with ETL / ELT tools and data pipeline orchestrationCertification in AWS,Snowflake,or Python is a plus. Job Title: Data Engineer (Snowflake,Python,AWS) .Certification in AWS,Snowflake,or Python is a plus.Preferred Qualifications: .",270525501411,"Automation,query optimization,Data modeling,data security,Analytical,Machine learning,Data processing,Data quality"
Python,Senior Python Developer - With AI/ML,BMC Software,8-13 Yrs,Not disclosed,Pune,/job-listings-senior-python-developer-with-ai-ml-bmc-software-india-pvt-ltd-pune-8-to-13-years-270525936916,". You have 8+ years of experience with application development using Python,Java,RESTful services,high-performance,and multi-threadingExperience with machine learning frameworks and libraries (e.g.,scikit-learn,TensorFlow,PyTorch)",270525936916,"Python,Java,DevOps,CSS,Artificial Intelligence,JavaScript,HTML,React"
Python,python developer,Xoriant,4-9 Yrs,Not disclosed,"Hybrid - Mumbai, Pune, Bengaluru",/job-listings-python-developer-xoriant-mumbai-pune-bengaluru-4-to-9-years-290525032392,"**Qualifications****Mumbai****Primary Responsibilities**The developer will be working within a machine learning team/squad. The team is working on developing Artificial Intelligence solutions including ML and Gen AI. The candidate should be familiar with python development and prompt engineering. The candidate should be able to work with different Clients/SMEs and understand the business requirements for prompt engineering and proper python code development. Experience with Open AI and different LLM models, conduct testing and performance evaluation is required. Good candidate should be familiar with ongoing monitoring.* Contribute to development and maintenance of the python library.* Contribute to the support of the library.* Participate in prompt engineering.* Maintain the prompts and keep them up to date with the new LLM versions* Conduct regular testing and performance analysis.* Participate in prompt benchmarking experiments.**Skills Required**\- Bachelors in computer science or related field\- Years of experience: 5+\- Hands-on experience in building python applications\- Excellent prompt engineering skills\- Excellent Python development skills\- Knowledge of design patterns, system resiliency, observability, scalability and performance\- Experience of Agile development\- Strong analytical skills and passion for problem-solving\- Good communication skills**Skills Desired**\- Experience with machine learning, vector databases\- Cloud-based application development preferably using Microsoft Azure Cloud\- Prior experience in FinTech application development\- Exposure to working in a global delivery team",290525032392,"GEN AI,Azure Cloud,Machine Learning,Python Development,Machine,Gen,Microsoft Azure,Artificial Intelligence"
Python,"Lead Data Analytics Engineer - Power BI, Snowflake, SQL, Python",Avalara India,8-13 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-lead-data-analytics-engineer-power-bi-snowflake-sql-python-avalara-india-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-8-to-13-years-300525503243,"Bachelors Engineering degree in Computer Science or a related fieldYou have deep SQL experience,an understanding of modern data stacks and technology,experience with data and all things data-related,and experience guiding a team through technical and design challengesExpert level experience in PowerBI,SQL and Snowflake .",300525503243,"Computer science,data science,Data modeling,Wellness,Data quality,Operations,Analytics,SQL"
Python,Python Developer,Total Shape,1-4 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-python-developer-total-shape-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-1-to-4-years-280525501795,"Location: Work From Home (Remote) . Salary: $1,200 - $1,500 USD / monthSolid experience in Python development .Experience working with APIs and data structures .",280525501795,"Backend,Automation,Front end,Web technologies,Social media,Django,Data structures,Troubleshooting"
Python,Apptware Solutions Senior Full Stack Developer Python/React.js,Apptware,5-7 Yrs,Not disclosed,Pune,/job-listings-apptware-solutions-senior-full-stack-developer-python-react-js-apptware-solutions-llp-pune-5-to-7-years-270525935266,Preferred SkillsExperience :5+ years,270525935266,"continuous integration,python,ci/cd,aws cognito,react.js,dynamo db,web application,unit testing"
Python,Senior Backend Developer - Python Programming,Sekel Tech,5-7 Yrs,Not disclosed,Pune,/job-listings-senior-backend-developer-python-programming-sekel-tech-pune-5-to-7-years-270525934006,"Bachelors degree in Computer Science,Engineering,Information Technology,or a related fieldWe are seeking a talented and experienced Backend Developer with strong proficiency in Python,Django,and AWS to join our growing team",270525934006,"Python,RESTful API,Django,MySQL,FastAPI,Server Side Component,ORM,Backend Architecture"
Python,Senior Python Developer - With AI/ML,BMC Software,8-13 Yrs,Not disclosed,Pune,/job-listings-senior-python-developer-with-ai-ml-bmc-software-india-pvt-ltd-pune-8-to-13-years-270525931538,". You have 8+ years of experience with application development using Python,Java,RESTful services,high-performance,and multi-threadingExperience with machine learning frameworks and libraries (e.g.,scikit-learn,TensorFlow,PyTorch)",270525931538,"Python,Java,CSS,Azure,data mining,SOLID principles,HTML,machine learning techniques"
Python,Python AWS Full Stack developer,Shashwath Solution,5-8 Yrs,Not disclosed,"Pune, Bengaluru",/job-listings-python-aws-full-stack-developer-shashwath-solution-pune-bengaluru-5-to-8-years-290525917920,"Python,AWS,DynamoDB,Opensearch Terraform (Good to have),ReactJS,Javascript,Typescript,HTML,CSS,Agile,Git,CI CD,Docker,Linux (Good to have),Good to have knowledge of ADAS Automative Good to have AWS certificationPREFERRED SKILLSGood to have knowledge of ADAS Automative. Should have hands-on AWS experience or Migration with AWS Knowledge and cloud-based applications and pipelines",290525917920,"Python,CSS,DynamoDB,Opensearch Terraform,HTML,CI CD,ADAS,Automative"
Python,Sr. Python Developer - AI/ML Skills,BMC Software,8-13 Yrs,Not disclosed,Pune,/job-listings-sr-python-developer-ai-ml-skills-bmc-software-india-pvt-ltd-pune-8-to-13-years-270525936914,"You have knowledge and experience with build tools such as Gradle and MavenYou have experience in a Web based environment utilizing React,Angular,server-side rendering,HTML,CSS,JavaScript and TypeScriptExperience with machine learning frameworks and libraries (e.g.,scikit-learn,TensorFlow,PyTorch)Experience with Agile methodology,use of Atlassian products Jira,Confluence)",270525936914,"Python,Java,CSS,PyTorch,scikit-learn,Artificial Intelligence,JavaScript,Fast API"
SQL,SQL Developer (Freelance),Soul Ai,4-8 Yrs,Not disclosed,Pune,/job-listings-sql-developer-freelance-soul-ai-pune-4-to-8-years-300525926072,"Designing database schemas. Proficient in working with relational database management systems like MySQL,PostgreSQL,or SQL Server. Why Join Us.1+ year of SQL development experience.",300525926072,"sql development,sql queries,database performance tuning,relational database management system,sql,schema,oracle,performance tuning"
SQL,SQL Developer (Freelance),Soul Ai,4-8 Yrs,Not disclosed,Bengaluru,/job-listings-sql-developer-freelance-soul-ai-bengaluru-4-to-8-years-300525926066,"Designing database schemas. Proficient in working with relational database management systems like MySQL,PostgreSQL,or SQL Server. Why Join Us.1+ year of SQL development experience.",300525926066,"sql development,sql queries,database performance tuning,relational database management system,sql,schema,oracle,performance tuning"
SQL,SQL Developer (Freelance),Soul Ai,4-8 Yrs,Not disclosed,Hyderabad,/job-listings-sql-developer-freelance-soul-ai-hyderabad-4-to-8-years-300525926063,"Designing database schemas. Proficient in working with relational database management systems like MySQL,PostgreSQL,or SQL Server. Why Join Us.1+ year of SQL development experience.",300525926063,"sql development,sql queries,database performance tuning,relational database management system,sql,schema,oracle,performance tuning"
SQL,SQL Developer (Freelance),Soul Ai,4-8 Yrs,Not disclosed,Chennai,/job-listings-sql-developer-freelance-soul-ai-chennai-4-to-8-years-300525926043,"Designing database schemas. Proficient in working with relational database management systems like MySQL,PostgreSQL,or SQL Server. Why Join Us.1+ year of SQL development experience.",300525926043,"sql development,sql queries,database performance tuning,relational database management system,sql,schema,oracle,performance tuning"
SQL,SQL Developer (Freelance),Soul Ai,4-8 Yrs,Not disclosed,Mumbai,/job-listings-sql-developer-freelance-soul-ai-mumbai-4-to-8-years-300525926003,"Designing database schemas. Proficient in working with relational database management systems like MySQL,PostgreSQL,or SQL Server. Why Join Us.1+ year of SQL development experience.",300525926003,"sql development,sql queries,database performance tuning,relational database management system,sql,schema,oracle,performance tuning"
SQL,SQL Developer (Freelance),Soul Ai,4-8 Yrs,Not disclosed,Kolkata,/job-listings-sql-developer-freelance-soul-ai-kolkata-4-to-8-years-300525925968,"Designing database schemas. Proficient in working with relational database management systems like MySQL,PostgreSQL,or SQL Server. Why Join Us.1+ year of SQL development experience.",300525925968,"sql development,sql queries,database performance tuning,relational database management system,sql,schema,oracle,performance tuning"
SQL,SQL Developer,Infosys BPM,2-5 Yrs,Not disclosed,Bengaluru,/job-listings-sql-developer-infosys-bpm-bengaluru-2-to-5-years-300525021013,"Preferred Qualifications: . Bachelors degree in Computer Science,Information Technology,or a related fieldExperience Required: 2 to 5 yearsNotice Period: Immediate joiners preferredRequired Skills: . 2 to 5 years of hands-on experience in SQL developmentThe ideal candidate will have strong experience in SQL development and a passion for working with data",300525021013,"SQL Development,SQL Coding,Sql Joins,SQL Queries,SQL Scripting,Coding,Join,SQL"
SQL,Oracle PL/SQL Developer,Godigi Infotech,0-1 Yrs,Not disclosed,"Mumbai, Hyderabad, Pune, Bengaluru",/job-listings-oracle-pl-sql-developer-godigi-infotech-mumbai-hyderabad-pune-bengaluru-0-to-1-years-191023500125,Preferred keyskills . PLSQL,191023500125,"IT services,Oracle Apps,Software QA,Backend,Oracle SQL,Consulting,Data processing,PLSQL"
SQL,PLSQL Developer/ PL/SQL Developer,Atyeti,2-4 Yrs,Not disclosed,"Hybrid - Pune, Chennai, Bengaluru",/job-listings-plsql-developer-pl-sql-developer-atyeti-pune-chennai-bengaluru-2-to-4-years-180525004331,"Bachelors degree in Computer Science,Information Technology,or a related fieldProven experience in data reconciliation projects or financial data matching. . Strong understanding of data structures,normalization,and relational databases. . Proficient in writing complex joins,subqueries,and performance-tuned SQL.Experience working with large datasets in structured environments.",180525004331,"Stored Procedures,PLSQL,Triggers,Cursor,SQL,Procedures,PLSQL Development,Development"
SQL,Oracle PL/SQL developer -Immediate Joiners,Candor Software Solutions,2-5 Yrs,Not disclosed,Chennai,/job-listings-oracle-pl-sql-developer-immediate-joiners-candor-software-solutions-chennai-2-to-5-years-300525014826,Location: Chennai . Work Model: Work from Office. Job Type: Full TimeThe ideal candidate must demonstrate strong problem-solving skills and a deep understanding of relational database concepts. . Key ResponsibilitiesRequired SkillsExperience: 2 to 5 years.Proven experience (2-4years) in Oracle PL / SQL development,300525014826,"Plsql Development,Views,functions,Triggers,Stored procedures,Functional,Procedures,SQL development"
SQL,SQL Server Developer,Maimsd Technology,2-7 Yrs,Not disclosed,"Kolkata, Pune, Chennai",/job-listings-sql-server-developer-maimsd-technology-kolkata-pune-chennai-2-to-7-years-300525922351,"**Location : Multiple location (** Delhi / NCR,Bangalore/Bengaluru,Hyderabad/Secunderabad,Chennai,Pune,Kolkata,Ahmedabad,Mumbai)**Employment Type : Full Time, Permanent****Working mode : Regular****Notice Period : Immediate - 15 Days**Required Skills & Qualifications :Experience :* 2+ years of experience working with SQL Server (2016 or newer) in a development capacity.* Strong experience in writing complex SQL queries, stored procedures, triggers, and functions.Database Design & Development :* Proficient in database design, normalization, and denormalization techniques.* Experience in creating and maintaining tables, indexes, views, and other database objects.* Experience with SQL Server Integration Services (SSIS)* Ability to work with large datasets and integrate data from multiple sources.Tools & Technologies :* Proficient in T-SQL, SSRS, SSIS, and SQL Server Management Studio (SSMS).* Familiarity with SQL Server Reporting Services (SSRS) and SQL Server Analysis Services (SSAS) is a plus.Version Control & Deployment :* Experience with source control systems like Git or SVN.* Familiarity with database deployment processes and change management.Problem-Solving & Communication :* Strong analytical and troubleshooting skills.* Excellent written and verbal communication skills, with the ability to work in a team-oriented environment.Preferred Qualifications :* Experience with cloud databases (e.g., Azure SQL Database).* Knowledge of data warehousing concepts and OLAP cubes.* Familiarity with Agile or Scrum methodologies.* Experience with Power BI or other data visualization tools.",300525922351,"SQL Server,T-SQL,Database Performance Tuning,Power BI,SSRS,Database Design,SSIS,ETL"
SQL,SQL Server Developer,Maimsd Technology,2-7 Yrs,Not disclosed,"Mumbai, New Delhi, Bengaluru",/job-listings-sql-server-developer-maimsd-technology-mumbai-new-delhi-bengaluru-2-to-7-years-300525916088,"Proficient in T-SQL,SSRS,SSIS,and SQL Server Management Studio (SSMS). . - Familiarity with SQL Server Reporting Services (SSRS) and SQL Server Analysis Services (SSAS) is a plus.2+ years of experience working with SQL Server (2016 or newer) in a development capacity. . - Strong experience in writing complex SQL queries,stored procedures,triggers,and functions.",300525916088,"SQL Server,T-SQL,Power BI,SSRS,Database Design,data warehousing,SSIS,Database Development"
SQL,Oracle Sql And Plsql Developer (Immediate joiner preferred),Cameo Corporate Services,3-5 Yrs,Not disclosed,Chennai,/job-listings-oracle-sql-and-plsql-developer-immediate-joiner-preferred-cameo-corporate-services-chennai-3-to-5-years-300525015535,Most preferred : Immediate Joiner / 15 days of Notice period,300525015535,"Query Optimization,Stored Procedures,PLSQL,Complex Queries,SQL,Query Tuning,Views,Query Writing"
SQL,Senior Microsoft SQL Developer,Luxoft,8-12 Yrs,Not disclosed,Pune,/job-listings-senior-microsoft-sql-developer-luxoft-india-llp-pune-8-to-12-years-190525913259,"We are building a team from offshore that will work with the existing team. . We require an experienced Microsoft SQL Developer with strong experience with Microsoft SQL Server with broad exposure to financial markets.Experience within Financial services preferred,ideally with exposure to the Banking and Finance data domainExperience in query optimization",190525913259,"sql queries,sql server,sql,stored procedures,troubleshooting,balance sheet,data analysis,interest rates"
SQL,Senior SQL Developer / DBA,Xoriant,4-8 Yrs,Not disclosed,"Hybrid - Mumbai, Pune, Bengaluru",/job-listings-senior-sql-developer-dba-xoriant-mumbai-pune-bengaluru-4-to-8-years-240425012253,"Support 24x7 production environments in a rotating shift schedule3+ years experience on perform database performance tuning and optimization to ensure high availability and efficiencyCloud expertise in databases,compute,storage,and networking (AWS preferred: EC2,CloudFormation,CloudWatch,Kubernetes)Experience in Ops / DevOps engineering with a software development mindset",240425012253,"database infrastructure,Cloud Technologies,SQL Development,MySQL,Infrastructure,DBMS,SQL,Senior"
SQL,PL/SQL Developer with Core Banking,Oracle,6-11 Yrs,15-22.5 Lacs PA,Hybrid - Pune,/job-listings-pl-sql-developer-with-core-banking-oracle-pune-6-to-11-years-210425008740,"Position Description . We are seeking aspirational graduates interested in a career in Consulting to join our niche Banking Domain and PracticeYour Skills & Experience . You must be a recent graduate or post graduate with 6 12 years or more of field experience. Good Knowledge in Oracle SQL,PL / SQL,and WebservicesShould have strong Oracle tech skills - PL / SQL,SQL,Java",210425008740,"flexcube,Core Banking,PLSQL,Core,Development,SQL"
SQL,Senior Automation Specialist - Python Automation + SQL,Oracle,5-7 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-senior-automation-specialist-python-automation-sql-oracle-india-pvt-ltd-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-5-to-7-years-310525501863,"Automation SpecialistAbout Oracle FSGIU - Finergy:The Finergy division within Oracle FSGIU is dedicated to the Banking, Financial Services, and Insurance (BFSI) sector. We offer deep industry knowledge and expertise to address the complex financial needs of our clients. With proven methodologies that accelerate deployment and personalization tools that create loyal customers, Finergy has established itself as a leading provider of end-to-end banking solutions. Our single platform for a wide range of banking services enhances operational efficiency, and our expert consulting services ensure technology aligns with our clients business goalsResponsibilities**Automation Engineering**Build automation solutions from the ground up and optimize existing frameworks for scalability and minimal maintenance.Tackle complex automation challenges across diverse technologies, ensuring solutions are robust, scalable, and easy to maintain.Drive continuous improvements in automation efficiency by leveraging innovative technologies and advanced testing strategies.**Testing Quality Assurance**Play a pivotal role in testing activities, team training, and bridging skill gaps across various applications.Develop and maintain comprehensive regression test suites for applications and systems.Effectively communicate test results and insights to stakeholders at all levels.Provide expert support to development, business, and testing teams on both internal and external issues.Conduct root cause analysis of defects and collaborate with engineering teams to resolve and validate fixes.Demonstrate strong leadership in guiding and mentoring team members.**Performance Testing**Support Quality Engineering (QE) initiatives, including performance testing of complex systems to ensure optimal application performance.**Agile Methodology**Demonstrate expertise in Agile methodologies, tools, and the Scrum framework.Experience working within platform operation models and POD structures.**Domain Knowledge**Possess a foundational understanding of banking concepts and industry practices.Mandatory Skills  **5 - 7 Years of Automation Experience** Python Automation - Hybrid / Data DrivenSQL QueriesIndependently work on automation frameworkKnowledge on Agile MethodologySDLC knowledge and familiarityGood to Have Skills* **Banking Domain Knowledge*** **Devops framework integration and maintenance - CI/CD*** **Version control and GIT experience*** **Selenium Automation**Self Test Questions_1) Do i have strong expertise on core java with relevant 5 years__2) Have i worked on Python and SQL for least 4 years__4) Do i gave good understanding on Agile methodology__5) Will i be able to work independently with my expertise on automation_**Screening Questions:**Tanaya will share 4-5 questions which can be used in prescreeningCareer Level - IC1Automation Specialist 2About Oracle FSGIU - Finergy:The Finergy division within Oracle FSGIU is dedicated to the Banking, Financial Services, and Insurance (BFSI) sector. We offer deep industry knowledge and expertise to address the complex financial needs of our clients. With proven methodologies that accelerate deployment and personalization tools that create loyal customers, Finergy has established itself as a leading provider of end-to-end banking solutions. Our single platform for a wide range of banking services enhances operational efficiency, and our expert consulting services ensure technology aligns with our clients business goalsResponsibilities**Automation Engineering**Build automation solutions from the ground up and optimize existing frameworks for scalability and minimal maintenance.Tackle complex automation challenges across diverse technologies, ensuring solutions are robust, scalable, and easy to maintain.Drive continuous improvements in automation efficiency by leveraging innovative technologies and advanced testing strategies.**Testing Quality Assurance**Play a pivotal role in testing activities, team training, and bridging skill gaps across various applications.Develop and maintain comprehensive regression test suites for applications and systems.Effectively communicate test results and insights to stakeholders at all levels.Provide expert support to development, business, and testing teams on both internal and external issues.Conduct root cause analysis of defects and collaborate with engineering teams to resolve and validate fixes.Demonstrate strong leadership in guiding and mentoring team members.**Performance Testing**Support Quality Engineering (QE) initiatives, including performance testing of complex systems to ensure optimal application performance.**Agile Methodology**Demonstrate expertise in Agile methodologies, tools, and the Scrum framework.Experience working within platform operation models and POD structures.**Domain Knowledge**Possess a foundational understanding of banking concepts and industry practices.Mandatory Skills  **5 - 7 Years of Automation Experience** Python Automation - Hybrid / Data DrivenSQL QueriesIndependently work on automation frameworkKnowledge on Agile MethodologySDLC knowledge and familiarityGood to Have Skills* **Banking Domain Knowledge*** **Devops framework integration and maintenance - CI/CD*** **Version control and GIT experience*** **Selenium Automation**Self Test Questions_1) Do i have strong expertise on core java with relevant 5 years__2) Have i worked on Python and SQL for least 4 years__4) Do i gave good understanding on Agile methodology__5) Will i be able to work independently with my expertise on automation_",310525501863,"Core Java,Manager Quality Assurance,Bfsi,Consulting,Performance testing,Scrum,Selenium,Oracle"
SQL,Oracle/SQL Developer with IICS (Informatica Intelligent ),Synechron,4-6 Yrs,Not disclosed,Bengaluru,/job-listings-oracle-sql-developer-with-iics-informatica-intelligent-synechron-technologies-pvt-ltd-bengaluru-4-to-6-years-280525929489,"Proven experience with ETL design,development,and management using Informatica Intelligent Cloud Services (IICS)Qualifications. Bachelors degree in Computer Science,Information Technology,or related fieldRequired: . Oracle SQL (latest stable versions or as specified by project)Preferred: . Data warehousing tools and technologiesExperience Requirements.",280525929489,"SQL,Azure,Data Quality,IICS,Git,GCP,PL/SQL Oracle,SQL Development"
SQL,Opening For SQL Developer (SSIS & C#),Infogain,3-6 Yrs,Not disclosed,"Hybrid - Noida, Pune, Bengaluru",/job-listings-opening-for-sql-developer-ssis-c-infogain-noida-pune-bengaluru-3-to-6-years-290525018289,Required Skills & Qualifications: . Hands-on experience with SSIS developmentExperience in database performance tuning and optimization,290525018289,"C#,SSIS,sql server,SQL Server Development,Serv,Server,Server SIDE Development,SQL"
SQL,Developer-SQL,Sapiens,4-9 Yrs,Not disclosed,Bengaluru,/job-listings-developer-sql-sapiens-technologies-1982-india-private-limited-bengaluru-4-to-9-years-290525940626,"Occasional travel for training,meetings,or trade shows may be requiredKnowledge and Skill Requirements / Specialized Courses and / or Helpful Training: . - Experience with the development and support of database driven applications using SQL,JavaScript (jQuery),AJAX,XML,HTML,and CSS",290525940626,"SQL,css,web application,ip networking,ajax,business intelligence,jquery,advanced ms excel"
SQL,Data Analyst - SQL/Python,Rbhu Etg,0-1 Yrs,Not disclosed,"Mumbai, Navi Mumbai, Pune",/job-listings-data-analyst-sql-python-rbhu-etg-private-limited-mumbai-navi-mumbai-pune-0-to-1-years-270525921251,"Requirements : We are looking for bright,young engineers with good mathematics skills and an interest in data analytics / science.",270525921251,"Python,Reporting Analytics,R,Power BI,Data Visualization,Data Analyst,Data Analytics,SQL"
SQL,SQL Developer,Impact Analytics,1-3 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-sql-developer-impact-analytics-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-1-to-3-years-210525504852,"What lands you in the role: 1- 3 years of relevant work experience as a SQL Developer or in a similar role . Bachelors degree in Computer Science,Information Technology,or a related field (or equivalent work experience) . Proficiency in SQL,including T-SQL for Microsoft SQL Server or PL / SQL for Oracle . Strong knowledge of database design principles,normalization,and indexing .",210525504852,"Performance tuning,Data modeling,Database design,Database management,PLSQL,Oracle,Database Administrator,Information technology"
SQL,PL/SQL Developer,Prodian,2-3 Yrs,Not disclosed,Chennai,/job-listings-pl-sql-developer-prodian-chennai-2-to-3-years-300525502478,"Requirements: . Proficiency in Oracle PL / SQL programming with experience in developing stored procedures,functions,and triggersExperience with ETL processes and data warehouse integration .",300525502478,"Unix,Performance tuning,Data analysis,Linux,RDBMS,Coding,Stored procedures,Troubleshooting"
SQL,Oracle PL/SQL Developer,Infosys,3-5 Yrs,Not disclosed,Bengaluru,/job-listings-oracle-pl-sql-developer-infosys-limited-bengaluru-3-to-5-years-200525923668,"Master Of Engineering,MBA,MSc,MTech,Bachelor of Engineering,BCom,BSc,BTech . Service LinePreferred .3+ years of experience in Implementation,Development,and Support projects related to Oracle PL / SQL-based Enterprise ApplicationsExperience with Oracle versions 10g,11g,12c,and higher.Analytical abilities,Strong Technical Skills,Good communication skills",200525923668,"oracle pl,plsql,debugging,software quality assurance,sql programming,sql development,12c,oracle"
SQL,SQL Developer,Qualitest,2-7 Yrs,Not disclosed,Bengaluru,/job-listings-sql-developer-qualitest-india-private-limited-bengaluru-2-to-7-years-310525502397,"Strong knowledge in SQL development and relational databases (2 years with MS SQL Server,additional experience with databases such as PostgreSQL / Oracle a plus)Experience with database design,indexing,normalization,and query optimization techniques (including performance profiling)Proven experience as an SQL Developer or in a similar role",310525502397,"MS SQL,query optimization,Data modeling,Database design,Postgresql,database security,Visual Studio,Oracle"
SQL,SQL Developer,IOSPL Technology Services Private Limited,4-9 Yrs,Not disclosed,"Noida, Hyderabad, Bengaluru",/job-listings-sql-developer-iospl-technology-services-private-limited-noida-hyderabad-bengaluru-4-to-9-years-200525931037,"Job Title: SQL DeveloperLocation: Bangalore, Hyderabad, Noida, Chennai & PuneNotice Period: ImmediateAbout the role:We are looking for a skilled SQL Developer with strong experience in SQL query development, data modeling, and query performance tuning. The ideal candidate will have expertise in database optimization and query execution plans.Key Responsibilities:Develop, optimize, and maintain complex SQL queries and stored procedures.Ensure high performance and availability of database systems.Analyze query performance and fine-tune SQL queries for better efficiency.Work closely with data architects and application developers to ensure smooth data operations.Troubleshoot and resolve database performance issues.Required Skills & Qualifications:Strong experience in SQL query development and performance tuning.In-depth understanding of database schema design and data modeling.Hands-on experience with Oracle, MySQL, or SQL Server databases.Oracle Database SQL Certification is a plus.Excellent analytical and problem-solving skills.Good communication skills to interact with stakeholders and teams effectively.Oracle DatabaseSQL QueriesDatabase designData ModelingMySQL",200525931037,"SQL,Query Optimization,PL/SQL,Oracle Database,Stored Procedures,MySQL,Database Design,SQL Queries"
SQL,JS/SQL Developer,Wolken Software,0-1 Yrs,Not disclosed,Bengaluru,/job-listings-js-sql-developer-wolken-software-pvt-ltd-bengaluru-0-to-1-years-210525503550,"Wolken Software Pvt Ltd is looking for JS/SQL Developer to join our dynamic team and embark on a rewarding career journey.Designing and implementing database structures, including tables, indexes, views, and stored proceduresWriting and testing SQL scripts, including complex queries and transactions, to support data analysis and application developmentMaintaining and optimizing existing database systems, troubleshooting performance issues and resolving data integrity problemsCollaborating with software developers, project managers, and other stakeholders to ensure that database designs meet business requirements and technical specificationsImplementing database security and access control measures, ensuring the confidentiality and protection of sensitive dataMonitoring database performance and scalability, and making recommendations for improvements. Excellent communication and interpersonal skills",210525503550,"Javascript,SQL,Development,SQL development"
SQL,SQL Developer - 5+ Year + Bengaluru,Crescendo Global Leadership Hiring India,5-10 Yrs,Not disclosed,Bengaluru,/job-listings-sql-developer-5-year-bengaluru-crescendo-global-leadership-hiring-india-bengaluru-5-to-10-years-300525015795,"Bachelors degree in Computer Science,Engineering,or related field. Whats in it for you: .Requirements : . 5+ years of proven experience as a SQL developerOur client is seeking a skilled professional with over 5 years of experience in SQL development to join their dynamic teamExperience with performance tuning and optimization techniques",300525015795,"SQL Server,SQL,Views,Stored Procedures,Tables,Complex Queries,Triggers,Complex"
SQL,SQL Developer (Senior),Infogain,8-11 Yrs,Not disclosed,Bengaluru,/job-listings-sql-developer-senior-infogain-india-p-ltd-bengaluru-8-to-11-years-230525502227,EXPERIENCE . 8-11 Years .,230525502227,"SQL queries,SUB,Postgresql,Database,PLSQL,SQL development,SQL,Development"
SQL,PL/SQL Developer,Saab Engineering,5-10 Yrs,Not disclosed,"Gurugram, Haryana",/job-listings-pl-sql-developer-saab-engineering-gurugram-haryana-5-to-10-years-300525922881,"Any graduation.Should have work experience India insurance domainGood at communication and understanding of requirementKnowledge of GCP cloud & BQ will be given preference5+ years experience in PL / SQL queries,database management,data modeling",300525922881,"PL/SQL,GCP - Cloud,Data Management,India Insurance Domain,PLSQL,Data Modeling,AWS,sql"
SQL,"Oracle Lead Developer (PL/SQL, FORMS and APEX) For Smart Materials",HTC Global Services,5-10 Yrs,Not disclosed,Chennai,/job-listings-oracle-lead-developer-pl-sql-forms-and-apex-for-smart-materials-htc-global-services-india-pvt-ltd-chennai-5-to-10-years-260525501102,"Should have adequate Management experienceGood IT experience and a sound knowledge of ORACLE PL / SQL,APEX,WEB services",260525501102,"Construction,Purchase,Usage,Web services,Oracle forms,PLSQL,Management,Apex"
SQL,C Developer (C SQL Unix),Gainwell Technologies,9-14 Yrs,Not disclosed,Remote,/job-listings-c-developer-c-sql-unix-gainwell-technologies-bengaluru-9-to-14-years-300525037449,"Expertise in Batch job automation and notification services. What you should expect in this roleWorking Experience with the following technologies: . C . Unix / Linux SystemsComplex SQL work experience and query tuning expertiseExperience working with Member,Managed Care,Provider,Financial,Claims domain is a plus",300525037449,"Unix,C Developer,SQL,C,Development"
SQL,Senior Oracle Pl Sql Developer,Maddisoft Solutions,10-20 Yrs,Not disclosed,Hyderabad,/job-listings-senior-oracle-pl-sql-developer-maddisoft-solutions-hyderabad-10-to-20-years-310525000122,"Location : Hyderabad,India . : Design,develop,test,maintain,and support batch applications using Oracle PL / SQL for Retail Commissions and Amortization.Monitor batch processes daily / weekly/monthly and resolve job failures as quickly as possibleExperience: . 15+ years of experience in Software development12+ years of experience in Oracle 12c or 19c",310525000122,"12C,Partitioning,Stored Procedures,Performance Tuning,Data WareHouse,PLSQL,19c,Procedures"
SQL,PL/SQL Developer with Core Banking,Oracle,6-11 Yrs,15-22.5 Lacs PA,"Hybrid - Chennai, Bengaluru, Mumbai (All Areas)",/job-listings-pl-sql-developer-with-core-banking-oracle-chennai-bengaluru-mumbai-all-areas-6-to-11-years-210425008649,"Position Description . We are seeking aspirational graduates interested in a career in Consulting to join our niche Banking Domain and PracticeYour Skills & Experience . You must be a recent graduate or post graduate with 6 12 years or more of field experience. Good Knowledge in Oracle SQL,PL / SQL,and WebservicesShould have strong Oracle tech skills - PL / SQL,SQL,Java",210425008649,"flexcube,Core Banking,PLSQL,Core,SQL,Development"
SQL,Oracle SQL & Java Developer,Teamware Solutions ( A division of Quantum Leap Co     nsulting Private LTD).,2-4 Yrs,Not disclosed,India,/job-listings-oracle-sql-java-developer-teamware-solutions-a-division-of-quantum-leap-co-nsulting-private-ltd-india-2-to-4-years-290525939862,Develop and maintain applications using Oracle SQL and Core Java.Design and implement databases and backend logic for various software solutions.,290525939862,"oracle,sql,plsql,java,oracle sql,python,performance tuning,maven"
SQL,Oracle SQL & Java Developer,Teamware Solutions ( A division of Quantum Leap Co     nsulting Private LTD).,2-4 Yrs,Not disclosed,"India, India",/job-listings-oracle-sql-java-developer-teamware-solutions-a-division-of-quantum-leap-co-nsulting-private-ltd-india-india-2-to-4-years-290525939535,Develop and maintain applications using Oracle SQL and Core Java.Design and implement databases and backend logic for various software solutions.,290525939535,"oracle,sql,plsql,java,oracle sql,python,performance tuning,maven"
SQL,ASP.Net Developer - C#/SQL Server,Maimsd Technology,5-8 Yrs,Not disclosed,"Mumbai, Patna, Bengaluru",/job-listings-asp-net-developer-c-sql-server-maimsd-technology-mumbai-patna-bengaluru-5-to-8-years-300525916109,"Experience with cloud platforms (e.g.,Azure). - Experience with API development (RESTful APIs). - Experience with front-end frameworks (e.g.,Angular,React). - Experience with DevOps practices. - Experience with continuous integration and continuous delivery (CI / CD) pipelines",300525916109,"ASP.Net,C#,CSS,Razor View Engines,JavaScript,.Net,HTML,SQL Server"
SQL,Oracle SQL/PLSQL Developer- Full Time (on Third Party Rolls),Hathway Cable Datacom,2-5 Yrs,2-4 Lacs PA,Mumbai (All Areas),/job-listings-oracle-sql-plsql-developer-full-time-on-third-party-rolls-hathway-cable-datacom-mumbai-all-areas-2-to-5-years-280525033688,"Develop Unix / Linux shell scripts for automation of batch jobs,monitoring,and reporting tasksPreferred candidate profile . .",280525033688,"Oracle SQL,Plsql Oracle,SQL,Third party,Development,Oracle development,Oracle,PLSQL Development"
SQL,Database Developer (SQL and Teradata),Synechron,5-9 Yrs,Not disclosed,Bengaluru,/job-listings-database-developer-sql-and-teradata-synechron-technologies-pvt-ltd-bengaluru-5-to-9-years-270525928931,"Bachelor s or Master s degree in Computer Science,Information Technology,or a related fieldExperience Requirements . 5 to 8 years of hands-on data development experienceTeradataAdvanced level,with performance tuning experienceProven experience in database design,data modeling,and data analysisExperience with software development methodologies and tools. . .",270525928931,"data warehousing,sql,etl,informatica,unix,data analysis,data management,performance tuning"
Spark,Big Data Developer - Spark/Hadoop,Maimsd Technology,7-10 Yrs,Not disclosed,Bengaluru,/job-listings-big-data-developer-spark-hadoop-maimsd-technology-bengaluru-7-to-10-years-300525922336,"\- The ideal candidate should also be capable of writing unit tests and maintaining documentation to ensure code quality and maintainability.- The role requires hands-on experience with the Hadoop ecosystem,particularly Spark (including Spark Streaming),Hive,Kafka,and Shell scripting",300525922336,"Spark,Hive,Shell Scripting,Hadoop,Cloud,Big Data,Data Modeling,Data Analytics"
Spark,Senior Data Engineer (Scala and Spark Expert),Synechron,4-9 Yrs,Not disclosed,Pune,/job-listings-senior-data-engineer-scala-and-spark-expert-synechron-technologies-pvt-ltd-pune-4-to-9-years-270525928938,"**Job Summary**Synechron is seeking a seasoned Senior Data Engineer with expertise in Scala and Spark to join our Data Engineering team. This role is critical in processing and transforming large datasets, contributing to Synechrons business objectives by harnessing the power of big data technologies. The Associate Specialist will leverage their extensive experience in data engineering to drive innovative solutions and ensure efficient data processing.**Software Requirements*****Required Software****Skills:*** * Proficiency in Scala and Spark for data processing and development.* Working knowledge of SQL and experience with relational databases.***Preferred Software****Skills:*** * Familiarity with other big data technologies and frameworks.**Overall Responsibilities*** Lead and execute data engineering projects using Scala and Spark, ensuring high-quality data solutions.* Collaborate with cross-functional teams to understand data requirements and deliver solutions that meet business needs.* Develop and maintain scalable data pipelines and processing systems.* Conduct code reviews to ensure the quality and maintainability of the codebase.* Stay updated with the latest advancements in big data technologies and incorporate them into existing solutions.* Troubleshoot and resolve technical issues, providing technical support to team members.**Technical Skills (By Category)*****Programming Languages:*** RequiredScala, SQL* PreferredKnowledge of additional programming languages used in big data environments.***Databases/Data Management:*** EssentialExperience with SQL databases and data management principles.***Frameworks and Libraries:*** EssentialApache Spark***Development Tools and Methodologies:*** RequiredFamiliarity with Agile methodologies.**Experience Requirements*** 7+ years of experience in big data, with significant exposure to Scala and Spark.* Proven track record in data engineering and processing large-scale datasets.**Day-to-Day Activities*** Participate in daily stand-up meetings and project planning sessions.* Collaborate with cross-functional teams to gather data requirements and design solutions.* Develop, test, and deploy data processing applications using Scala and Spark.* Conduct code reviews and provide feedback to other developers.* Stay informed about the latest trends in big data technologies.* Provide technical support and troubleshoot issues as they arise.**Qualifications*** Bachelor’s or Master’s degree in Computer Science, Information Technology, or a related field.* Relevant certifications in data engineering or big data technologies are preferred.* Commitment to continuous professional development and staying updated on industry trends.**Professional Competencies*** Strong critical thinking and problem-solving capabilities.* Effective teamwork and leadership abilities.* Excellent communication and stakeholder management skills.* Adaptability to new technologies and learning orientation.* Innovation mindset to drive creative solutions and improvements.* Effective time and priority management skills.__",270525928938,"scala,data processing,spark,stakeholder management,big data,hive,python,data management"
Spark,"Genpact Hiring For AWS data engineer with Kafka, Spark",Genpact,5-10 Yrs,Not disclosed,"Hybrid - Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR",/job-listings-genpact-hiring-for-aws-data-engineer-with-kafka-spark-genpact-hyderabad-secunderabad-bangalore-bengaluru-delhi-ncr-5-to-10-years-270525024109,"Genpact (NYSE: G) is a global professional services and solutions firm delivering outcomes that shape the future. Our 125,000+ people across 30+ countries are driven by our innate curiosity, entrepreneurial agility, and desire to create lasting value for clients. Powered by our purpose the relentless pursuit of a world that works better for people – we serve and transform leading enterprises, including the Fortune Global 500, with our deep business and industry knowledge, digital operations services, and expertise in data, technology, and AI.Inviting applications for the role of **Lead Consultant-Data Engineer, AWS+Python, Spark, Kafka for ETL!**Responsibilities* Develop, deploy, and manage ETL pipelines using AWS services, Python, Spark, and Kafka.* Integrate structured and unstructured data from various data sources into data lakes and data warehouses.* Design and deploy scalable, highly available, and fault-tolerant AWS data processes using AWS data services (Glue, Lambda, Step, Redshift)* Monitor and optimize the performance of cloud resources to ensure efficient utilization and cost-effectiveness.* Implement and maintain security measures to protect data and systems within the AWS environment, including IAM policies, security groups, and encryption mechanisms.* Migrate the application data from legacy databases to Cloud based solutions (Redshift, DynamoDB, etc) for high availability with low cost* Develop application programs using Big Data technologies like Apache Hadoop, Apache Spark, etc with appropriate cloud-based services like Amazon AWS, etc.* Build data pipelines by building ETL processes (Extract-Transform-Load)* Implement backup, disaster recovery, and business continuity strategies for cloud-based applications and data.* Responsible for analysing business and functional requirements which involves a review of existing system configurations and operating methodologies as well as understanding evolving business needs* Analyse requirements/User stories at the business meetings and strategize the impact of requirements on different platforms/applications, convert the business requirements into technical requirements* Participating in design reviews to provide input on functional requirements, product designs, schedules and/or potential problems* Understand current application infrastructure and suggest Cloud based solutions which reduces operational cost, requires minimal maintenance but provides high availability with improved security* Perform unit testing on the modified software to ensure that the new functionality is working as expected while existing functionalities continue to work in the same way* Coordinate with release management, other supporting teams to deploy changes in production environmentQualifications we seek in you!Minimum Qualifications* Experience in designing, implementing data pipelines, build data applications, data migration on AWS* Strong experience of implementing data lake using AWS services like Glue, Lambda, Step, Redshift* Experience of Databricks will be added advantage* Strong experience in Python and SQL* Proven expertise in AWS services such as S3, Lambda, Glue, EMR, and Redshift.* Advanced programming skills in Python for data processing and automation.* Hands-on experience with Apache Spark for large-scale data processing.* Experience with Apache Kafka for real-time data streaming and event processing.* Proficiency in SQL for data querying and transformation.* Strong understanding of security principles and best practices for cloud-based environments.* Experience with monitoring tools and implementing proactive measures to ensure system availability and performance.* Excellent problem-solving skills and ability to troubleshoot complex issues in a distributed, cloud-based environment.* Strong communication and collaboration skills to work effectively with cross-functional teams.Preferred Qualifications/ Skills* Master’s Degree-Computer Science, Electronics, Electrical.* AWS Data Engineering & Cloud certifications, Databricks certifications* Experience with multiple data integration technologies and cloud platforms* Knowledge of Change & Incident Management process**Genpact is an Equal Opportunity Employer and considers applicants for all positions without regard to race, color, religion or belief, sex, age, national origin, citizenship status, marital status, military/veteran status, genetic information, sexual orientation, gender identity, physical or mental disability or any other characteristic protected by applicable laws.** Genpact is committed to creating a dynamic work environment that values diversity and inclusion, respect and integrity, customer focus, and innovation. Get to know us at genpact.com and on LinkedIn, X, YouTube, and Facebook.Furthermore, please do note that Genpact does not charge fees to process job applications and applicants are not required to pay to participate in our hiring process in any other way. Examples of such scams include purchasing a 'starter kit,' paying to apply, or purchasing equipment or training.",270525024109,"Kafka,Spark,Aws Glue,AWS,Python,Pyspark,Aws Cloud,Aws Lambda"
Spark,"Sr. Data Engineer (Hadoop, Spark)",Visa,2-7 Yrs,Not disclosed,Bengaluru,/job-listings-sr-data-engineer-hadoop-spark-visa-inc-bengaluru-2-to-7-years-280525501362,"Visa is seeking highly energetic, passionate, technology enthusiast for Data Engineering team.The successful candidate will work as a Senior Data Engineer and be part of the Risk Solution Services team to design and develop solutions for all data requirements. The ideal candidate will bring robust technical strength in developing solutions in extremely high volume, low latency ETL workflow design and also bring an excellent understanding of data. This role will participate in design discussions, create solutions, develop programs and ensure successful delivery of business capabilities. This role will assume technical ownership of multiple applications and create robust and scalable solutions.Visa provides a challenging environment of volume, velocity and variety that is rarely matched.Candidates looking forward to thrive in such environment are encouraged to apply.**Responsibilities :*** Experience on developing, maintaining and supporting big data ETL pipelines (Hadoop, Hive, Spark)* Responsible for the implementation and test of scalable distributed ensuring security, timeliness and quality of data.* Experience supporting production systems* Work closely with other engineers and peers to design and develop ETL pipelines* Work with product managers in understanding and clarifying on the requirements* Demonstrate inclination towards continuous learning and professional development.* Proven track record of quickly acquiring new skills and knowledge in a fast-paced environment.This is a hybrid position. Expectation of days in office will be confirmed by your Hiring Manager.Basic Qualifications2+ years of relevant work experience and a Bachelors degree, OR 5+ years of relevant work experiencePreferred Qualifications3 or more years of work experience with a Bachelor s Degree or more than 2 years of work experience with an Advanced Degree (e.g. Masters, MBA, JD, MD)Bachelors in Computer Science, or Information Systems or related field from one of the top institutes5+ years of experience in data technologies and applications development4+ years of experience in Hadoop using Core Java Programming, Scala, Spark, Kafka , Hive on Linux/Unix environment.Working knowledge of Hadoop ecosystem and associated technologies, (For e.g. Apache Spark, etc.)Experience in writing Spark and Hive code to process large data sets in Hadoop environmentsStrong experience with SQL for extracting, aggregating, and processing big data using HadoopDevelopment experience in one or more of the following: Scala, Python or Java.Basic experience with Unix/Shell or Python scriptingExposure to Scheduling tools like Airflow and Control - M will be a plusExperience using VCS like GitBasic understanding of RDBMs viz, MS SQL, DB2, Oracle, etc for data retrievalUnderstanding of Kafka, Apache Hudi is a plus.Thrive in self-motivated internal-innovation driven environment.Adapting fast to new application knowledge and changes.",280525501362,"Unix,Computer science,Core Java,MS SQL,Linux,Db2,RDBMS,Workflow"
Spark,"Data Engineering Lead - AWS , Python, Spark ,Scala, Devops - HYD",Optum,6-11 Yrs,Not disclosed,Hyderabad,/job-listings-data-engineering-lead-aws-python-spark-scala-devops-hyd-optum-global-solutions-india-private-limited-hyderabad-6-to-11-years-270525929768,"Required QualificationsShell scripting,Orchestration (Airflow or MWAA preferred)CI / CD (Git preferred and experience with Deployment pipelines),Devops (including supporting production stack and working with SRE teams). 1+ Years of experience - Infrastructure as code (Terraform preferred). 1+ Years of experience - Spark streaming. Healthcare Domain & Data Standards .",270525929768,"continuous integration,python,spark streaming,spark,aws,container networking,glue,scala"
Spark,Software Engineer III - Python / Spark Big Data,JPMorgan Chase Bank,3-8 Yrs,Not disclosed,Mumbai,/job-listings-software-engineer-iii-python-spark-big-data-jp-morgan-chase-mumbai-3-to-8-years-200525501248,"Formal training or certification on software engineering concepts and 3+ years applied experienceRequired qualifications,capabilities,and skills .Preferred qualifications,capabilities,and skillsExperience with Big Data solutions or Relational DBExperience in Financial Service Industry is nice to have. .",200525501248,"System architecture,Coding,Artificial Intelligence,Debugging,Machine learning,Agile,System design,Application development"
Spark,Databricks Developer + Spark,Wissen Technology,2-6 Yrs,Not disclosed,Pune,/job-listings-databricks-developer-spark-wissen-infotech-pvt-ltd-pune-2-to-6-years-280525503174,. We are seeking a skilled . Databrick Certified Engineer . with a strong background in . Spark/Experience: . 7+Proven experience as a Databricks developer with,280525503174,"Telecom,Manager Quality Assurance,Coding,spark,Consulting,Manager Technology,Healthcare,HTML"
Spark,Big Data (Apache Spark) Developer,Opus Technologies,5-10 Yrs,Not disclosed,Hybrid - Pune,/job-listings-big-data-apache-spark-developer-opus-technologies-pune-5-to-10-years-200325012076,"A bachelors or master s degree in computer science,Engineering,or a related disciplineDatabase modelling and working with any of the SQL or NoSQL Database is mustExperience of working with Cloudera is PreferredExperience: 4+ YrsWorking experience of Version controls like Git,build tools like Maven is recommended",200325012076,"Java,Scala,Big Data,Apache Spark,Apache,Spark,Data,Development"
Spark,Azure Data Bricks Engineer - Kafka/Spark/SQL,CARBYNETECH,3-8 Yrs,Not disclosed,Hyderabad,/job-listings-azure-data-bricks-engineer-kafka-spark-sql-carbynetech-india-pvt-ltd-hyderabad-3-to-8-years-270525931088,"Azure Data Factory:\- Develop Azure Data Factory Objects - ADF pipeline, configuration, parameters, variables, Integration services runtime\- Hands-on knowledge of ADF activities(such as Copy, SP, lkp etc) and DataFlows\- ADF data Ingestion and Integration with other servicesAzure Databricks:\- Experience in Big Data components such as Kafka, Spark SQL, Dataframes, HIVE DB etc implemented using Azure Data Bricks would be preferred.\- Azure Databricks integration with other services\- Read and write data in Azure Databricks\- Best practices in Azure DatabricksSynapse Analytics:\- Import data into Azure Synapse Analytics with and without using PolyBase\- Implement a Data Warehouse with Azure Synapse Analytics\- Query data in Azure Synapse Analytics",270525931088,"Azure,Azure Data Factory,Data Ingestion,Hive,Kafka,Big Data,Azure Databricks,Spark"
Spark,Data Engineer with Spark & AWS,Caspex Corp,8-12 Yrs,Not disclosed,Hybrid - Hyderabad,/job-listings-data-engineer-with-spark-aws-caspex-corp-hyderabad-8-to-12-years-220525018297,Job Requirements: . Bachelors degree in computer science or equivalent6+ years of software development experienceWillingness to support production schedules,220525018297,"Spark,AWS,Java,SCALA,Data"
Spark,"Sr Data Engineer (Bigdata, Spark & Java/Go)",Visa,3-8 Yrs,Not disclosed,Bengaluru,/job-listings-sr-data-engineer-bigdata-spark-java-go-visa-inc-bengaluru-3-to-8-years-260525502405,"Expertise in Distributed Systems: Proven experience in designing,developing,and maintaining large-scale distributed systemsMasters,MBA,JD,MD). Bachelors degree in Computer Science,or related technical disciplineWith 3+ years of overall software development experience in building PaaS or Application frameworks.",260525502405,"Automation,GIT,Configuration management,Instrumentation,Scrum,Agile methodology,Open source,Distribution system"
Spark,Bigdata ( Spark /Scala+ Python) developers,Synechron,4-9 Yrs,Not disclosed,Bengaluru,/job-listings-bigdata-spark-scala-python-developers-synechron-technologies-pvt-ltd-bengaluru-4-to-9-years-270525928936,"Bachelors or Masters degree in Computer Science,Information Technology,or related fieldGood understanding of software architecture and design patternsAt least 5-12years of experience in software development and leading technology projectsExperience in mentoring and guiding junior team membersExperience in working with cross-functional teams. .",270525928936,"python,scala,artificial intelligence,spark,blockchain,emerging technologies,project management,software development"
Spark,"Data Engineer (AWS Redshift, Kubernetes, Spark and Python)",Synechron,5-10 Yrs,Not disclosed,Gurugram,/job-listings-data-engineer-aws-redshift-kubernetes-spark-and-python-synechron-technologies-pvt-ltd-gurugram-5-to-10-years-270525928991,"**Job Summary**As a Data Engineer at Synechron, you will play a pivotal role in harnessing data to drive business value. Your expertise will be essential in developing and maintaining data pipelines, ensuring data integrity, and facilitating analytics that inform strategic decisions. This role contributes significantly to our business objectives by optimizing data processing and enabling insightful reporting across the organization.**Software Requirements*****Required:*** AWS Redshift (3+ years of experience)* Spark (3+ years of experience)* Python (3+ years of experience)* Complex SQL (3+ years of experience)* Shell scripting (2+ years of experience)* Docker (2+ years of experience)* Kubernetes (2+ years of experience)* Bitbucket (2+ years of experience)***Preferred:*** DBT* Dataiku* Kubernetes cluster management**Overall Responsibilities*** Develop and optimize data pipelines using big data technologies, ensuring seamless data flow and accessibility.* Collaborate with cross-functional teams to translate business requirements into technical solutions.* Ensure high data quality and integrity in analytics and reporting processes.* Implement data architecture and modeling best practices to support strategic objectives.* Troubleshoot and resolve data-related issues, maintaining a service-first mentality to enhance customer satisfaction.**Technical Skills (By Category)*****Programming Languages:*** EssentialPython, SQL* PreferredShell scripting***Databases/Data Management:*** EssentialAWS Redshift, Hive, Presto* PreferredDBT***Cloud Technologies:*** EssentialAWS* PreferredKubernetes, Docker***Frameworks and Libraries:*** EssentialSpark* PreferredDataiku***Development Tools and Methodologies:*** EssentialBitbucket, Airflow or Argo Workflows**Experience Requirements*** 6-7 years of experience in data engineering or related roles.* Strong understanding of data & analytics concepts, with proven experience in big data technologies.* Experience in the financial services industry preferred but not required.* Alternative pathwaysSignificant project experience in data architecture and analytics.**Day-to-Day Activities*** Design and implement scalable data pipelines.* Participate in regular team meetings to align on project goals and deliverables.* Collaborate with stakeholders to refine data processes and analytics.* Make informed decisions on data management strategies and technologies.**Qualifications*** Bachelors degree in Computer Science, Data Engineering, or a related field (or equivalent experience).* Certifications in AWS or relevant data engineering technologies preferred.* Commitment to continuous professional development in data engineering and analytics.**Professional Competencies*** Strong critical thinking and problem-solving capabilities, with a focus on innovation.* Effective communication skills and stakeholder management.* Ability to work collaboratively in a team-oriented environment.* Adaptability and a willingness to learn new technologies and methodologies.* Excellent time and priority management to meet deadlines and project goals.__",270525928991,"kubernetes,python,amazon redshift,docker,stakeholder management,hive,cluster management,data management"
Spark,"Big data developer - Spark, Scala, Pyspark Coding & scripting",Wipro,5-8 Yrs,Not disclosed,Bengaluru,/job-listings-big-data-developer-spark-scala-pyspark-coding-scripting-wipro-limited-bengaluru-5-to-8-years-160525939417,"Proficient in . Spark,Scala,Pyspark coding & scriptingCandidates should be fluent in the Python / Scala languageHands-on experience in Big DataGood Knowledge of Hadoop Eco SystemEnsure good quality of interaction with customer w.r.t",160525939417,"hive,scala,pyspark,spark,hadoop,big data administration,cloudera,continuous integration"
Spark,"Data Engineer (ETL, Big Data, Hadoop, Spark, GCP), AS",Deutsche Bank,4-9 Yrs,Not disclosed,Pune,/job-listings-data-engineer-etl-big-data-hadoop-spark-gcp-as-deutsche-bank-ag-pune-4-to-9-years-090525913053,"Successful candidates should be able to work in a cross application mixed technical environment and must demonstrate solid hands-on development track record while working on an agile methodologySuccessful candidate should be able to work independently on medium to large sized projects with strict deadlinesProficient in Hadoop,Python,Spark,SQL Unix and Hive",090525913053,"hive,python,spark,unix sql,hadoop,continuous integration,load balancing,cloud orchestration"
Spark,"Data Engineer (ETL, Big Data, Hadoop, Spark, GCP)",Deutsche Bank,4-9 Yrs,Not disclosed,Pune,/job-listings-data-engineer-etl-big-data-hadoop-spark-gcp-deutsche-bank-ag-pune-4-to-9-years-090525913043,"Successful candidates should be able to work in a cross application mixed technical environment and must demonstrate solid hands-on development track record while working on an agile methodologySuccessful candidate should be able to work independently on medium to large sized projects with strict deadlinesProficient in Hadoop,Python,Spark,SQL Unix and Hive",090525913043,"hive,spark,unix sql,hadoop,python,continuous integration,load balancing,ci/cd"
Spark,Databricks Developer + Spark,Wissen Technology,2-6 Yrs,Not disclosed,Mumbai,/job-listings-databricks-developer-spark-wissen-infotech-pvt-ltd-mumbai-2-to-6-years-280525503173,We are seeking a skilled . Databrick Certified Engineer . with a strong background in .Experience : . 7Proven experience as a Databricks developer with,280525503173,"Telecom,Manager Quality Assurance,Coding,spark,Consulting,Manager Technology,Healthcare,HTML"
Spark,Spark Developer,Infosys,2-5 Yrs,5-15 Lacs PA,"Hybrid - Hyderabad, Pune, Bengaluru",/job-listings-spark-developer-infosys-hyderabad-pune-bengaluru-2-to-5-years-260225005472,"Experience with Spark SQL and DataFramesGood exposure to Big Data architectures and good understanding of Big Data eco systemExperience with some framework building experience on HadoopGood with DB knowledge with SQL tuning experienceGood to have experience with Python,APIs and exposure to Kafka. .",260225005472,"Spark developer,Pyspark,Spark sql,Big Data,Spark,Python,SQL,Development"
Spark,Sciative Solutions Data Engineer Python/Spark,Sciative Solutions,2-4 Yrs,Not disclosed,"Mumbai, Hyderabad",/job-listings-sciative-solutions-data-engineer-python-spark-sciative-solutions-mumbai-hyderabad-2-to-4-years-230525918403,"Solid understanding of data engineering concepts,data modeling,and data integration techniques. Proficiency in programming languages such as Python,SQL and Web Scrapping. Understanding of databases like No Sql,relational database,In Memory database and technologies like MongoDB,Redis,Apache Spark would be add on.",230525918403,"web scraping,data engineering,artificial intelligence,data modeling,data integration,python,big data technologies,dbms"
Spark,CarbyneTech - Azure Data Bricks Engineer - Kafka/Spark/SQL (3-8 yrs),CARBYNETECH,3-8 Yrs,Not disclosed,Hyderabad,/job-listings-carbynetech-azure-data-bricks-engineer-kafka-spark-sql-3-8-yrs-carbynetech-india-pvt-ltd-hyderabad-3-to-8-years-220525933684,"Azure Data Factory:\- Develop Azure Data Factory Objects - ADF pipeline, configuration, parameters, variables, Integration services runtime\- Hands-on knowledge of ADF activities(such as Copy, SP, lkp etc) and DataFlows\- ADF data Ingestion and Integration with other servicesAzure Databricks:\- Experience in Big Data components such as Kafka, Spark SQL, Dataframes, HIVE DB etc implemented using Azure Data Bricks would be preferred.\- Azure Databricks integration with other services\- Read and write data in Azure Databricks\- Best practices in Azure DatabricksSynapse Analytics:\- Import data into Azure Synapse Analytics with and without using PolyBase\- Implement a Data Warehouse with Azure Synapse Analytics\- Query data in Azure Synapse AnalyticsApplyInsightsFollow-upSave this job for future reference ____Did you find something suspiciousReport Here!__Hide This JobClick here to hide this job for you. You can also choose to hide all the jobs from the recruiter. __",220525933684,"hive,spark,big data,kafka,db,scala,data warehousing,pyspark"
Spark,Lead Data Engineer - Spark / Python,Unicon Connectors,5-7 Yrs,Not disclosed,Chennai,/job-listings-lead-data-engineer-spark-python-unico-connect-private-limited-chennai-5-to-7-years-190525909674,"Responsibilities for this position include :\- Provides technical leadership in Big Data space (Hadoop Stack like M/R, HDFS, Pig, Hive, HBase, Flume, Sqoop, NoSQL stores like Cassandra, HBase etc) across Fractal and contributes to open source Big Data technologies\- Write and tune complex Java, MapReduce, Pig and Hive jobs- Adapt quickly to change in requirements and be willing to work with different technologies if required\- Experience leading a Backend/Distributed Data Systems team while remaining hands-on is very important- Lead the effort to build, implement and support the data infrastructure\- Manage the business intelligence team and vendor partners, ensuring to prioritize projects according to customer and internal needs, and develops top-quality dashboards using industry best practices- Manage team of data engineers (both full-time associates and/or third party resources)\- Own the majority of deliverables for the Big Data team from a delivery perspective- Analyzes and confirms the integrity of source data to be evaluated- Leads in deployment and auditing models and attributes for accuracyEducation for Lead Data Engineer :Have a relevant degree such as Bachelor's and Master's Degree in Computer Science, Engineering, Statistics, Education, Technical, Information Technology, Information Systems, Mathematics, Computer Engineering, Management Skills for Lead Data EngineerDesired skills for lead data engineer include :- Python- Spark- Java- Hive- SQL- Hadoop architecture- Large scale search applications and building high volume data pipelines- Message queuing- NoSQL\- ScalaDesired experience for lead data engineer includes :- Experience in development utilizing C# .NET 4.5\- Experience in managing a live service that customers depend- Experience in coaching and managing other engineers- Be a team player and enjoy collaboration with other engineers and teams- Experience with software version management systems- Experience with task/bug tracking softwareExp : 5-7yrs",190525909674,"Python,Data Engineering,Hadoop,Big Data,HDFS,Spark,Distributed Systems,Distribution system"
Spark,Lead Data Engineer - Spark/Python,Unicon Connectors,5-7 Yrs,Not disclosed,Jaipur,/job-listings-lead-data-engineer-spark-python-unico-connect-private-limited-jaipur-5-to-7-years-190525906657,"Have a relevant degree such as Bachelors and Masters Degree in Computer Science,Engineering,Statistics,Education,Technical,Information Technology,Information Systems,Mathematics,Computer Engineering,Management.",190525906657,"Python,Data Engineering,Hadoop,Big Data,Hadoop architecture,Spark,Distributed Systems,Data"
Spark,Lead Data Engineer - Spark/Python,Unicon Connectors,5-7 Yrs,Not disclosed,Mumbai,/job-listings-lead-data-engineer-spark-python-unico-connect-private-limited-mumbai-5-to-7-years-190525906656,"Have a relevant degree such as Bachelors and Masters Degree in Computer Science,Engineering,Statistics,Education,Technical,Information Technology,Information Systems,Mathematics,Computer Engineering,Management.",190525906656,"SQL,Data Engineering,Hadoop,Big Data,HDFS,Spark,Distributed Systems,Python"
Spark,SPARK Data Onboarding Engineer,Photon,5-10 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-spark-data-onboarding-engineer-photon-infotech-p-ltd-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-5-to-10-years-130125505812,"Key Responsibilities: Data Engineering Development: . Design,develop,and test PySpark-based applications to process,transform,and analyze large-scale datasets from various sources,including relational databases,NoSQL databases,batch files,and real-time data streamsQualifications and Skills: . Bachelors degree in Computer Science,Information Technology,or a related field",130125505812,"Computer science,Data analysis,Analytical,Data structures,Data processing,Data quality,Apache,Information technology"
Spark,Big Data Engineer - (Hadoop/Hive/python/Spark/Scala),Capco,4-8 Yrs,Not disclosed,Bengaluru,/job-listings-big-data-engineer-hadoop-hive-python-spark-scala-capco-technologies-pvt-ltd-bengaluru-4-to-8-years-140525915046,"**Job TitleSenior Data Engineer/Developer****Number of Positions2****About The Role :**The Senior Data Engineer will be responsible for designing, developing, and maintaining scalable data pipelines and building out new API integrations to support continuing increases in data volume and complexity. They will collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.**Responsibilities:*** Design, construct, install, test and maintain highly scalable data management systems & Data Pipeline.* Ensure systems meet business requirements and industry practices.* Build high-performance algorithms, prototypes, predictive models, and proof of concepts.* Research opportunities for data acquisition and new uses for existing data.* Develop data set processes for data modeling, mining and production.* Integrate new data management technologies and software engineering tools into existing structures.* Create custom software components and analytics applications.* Install and update disaster recovery procedures.* Collaborate with data architects, modelers, and IT team members on project goals.* Provide senior level technical consulting to peer data engineers during data application design and development for highly complex and critical data projects.**Qualifications:*** Bachelor's degree in computer science, Engineering, or related field, or equivalent work experience.* Proven 5-8 years of experienceas a Senior Data Engineer or similar role.* Experience with big data toolsHadoop, Spark, Kafka, Ansible, chef, Terraform, Airflow, and Protobuf RPC etc.* Expert level SQL skills for data manipulation (DML) and validation (DB2).* Experience with data pipeline and workflow management tools.* Experience with object-oriented/object function scripting languagesPython, Java, Go langetc.* Strong problem solving and analytical skills.* Excellent verbal communication skills.* Good interpersonal skills.* Ability to provide technical leadership for the team.",140525915046,"sql,java,spark,data manipulation,kafka,hive,algorithms,dml"
Spark,Big Data Scala - Spark Developer,Blismos Solutions,2-5 Yrs,Not disclosed,Bengaluru,/job-listings-big-data-scala-spark-developer-blismos-solutions-pvt-ltd-bengaluru-2-to-5-years-110724502800,"Collaborate with data scientists,data analysts,and other stakeholders to develop predictive models and algorithms that drive insights and decision making . 2 to 5 years experience / End to end Big Data Stack Knowledge / Specialized in Scala Spark",110724502800,"hive,scala,big data technologies,apache pig,data architecture,hibernate,sql,spring"
Spark,"Data Engineer (Spark, Scala)-Drive 26 Apr",Metafolks,3-7 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-data-engineer-spark-scala-drive-26-apr-metafolks-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-3-to-7-years-260425502055,"As a Data Engineer, your responsibilities will include:Design and build data pipelines to process terabytes of dataOrchestrate in Airflow the data tasks to run on Kubernetes/Hadoop for the ingestion, processingand cleaning of data.Create Docker images for various applications and deploy them on KubernetesDesign and build best in class processes to clean and standardize data.Troubleshoot production issues in our Elastic EnvironmentTuning and optimizing data processesAdvancing the team s DataOps culture (CI/CD, Orchestration, Testing, Monitoring) and buildingout standard development patternsDrive innovation by testing new technology and approaches to continually advance thecapability of the data engineering function.Drive efficiencies in current engineering processes via standardization and migration of existingon-premises processes to the cloudEnsuring Data Quality building best in class data quality monitoring that ensure that all dataproducts exceed customer expectations.Required Qualifications:Computer Science bachelor s degree or similar.Good understanding of Data Modelling techniques i.e. DataVault, Kimble StarExcellent understanding of Column-Store RDBMS (DataBricks, Snowflake, Redshift, Vertica,Clickhouse)Good experience handling real-time, near real-time and batch data ingestionsHands on experience on the following technologies:o Developing processes in Sparko Writing complex SQL querieso Building ETL/data pipelineso Exposure to Kubernetes and Linux containers (i.e. Docker)o Related/complementary open-source software platforms and languages (e.g. Scala, Python,Java, Linux)Proven track record of designing effective data strategies and leveraging modern dataarchitectures that resulted in business valueExperience building cloud-native data pipelines on either AWS, Azure or GCP, following bestpractices in cloud deploymentsStrong DataOps experience (CI/CD, Orchestration, Testing, Monitoring)Demonstrated effective interpersonal, influence, collaboration and listening skillsStrong stakeholder management skillsExcellent time management, organizational and prioritization skills with ability to balancemultiple priorities.Preferred Qualifications:Experience with data tokenization and different techniques and tools i.e. DataVant, ProtegrityExperience with Azure Data Factory, Databricks and SnowflakeExperience with Apache Spark and related Big Data stack and technologies, PySpark ScalaExperience working with Apache Kafka, building appropriate producer/consumer appsExperience working with Kubernetes and Docker, and knowledgeable about cloud infrastructureautomation and management (e.g., Terraform)Experience working in projects with agile/scrum methodologiesHealthcare industry knowledge and experience with exposure",260425502055,"Computer science,Automation,Linux,GCP,RDBMS,Healthcare,Data quality,Open source"
Spark,Lead Data Engineer - Spark / Scala,Forward Eye Technologies,7-10 Yrs,Not disclosed,"Mumbai, Pune, Bengaluru",/job-listings-lead-data-engineer-spark-scala-forward-eye-technologies-mumbai-pune-bengaluru-7-to-10-years-020525913692,"**Notice Period :** Immediate to 15 Days.**Location :** Bangalore, Hyderabad, Mumbai, Pune, Nagpur, Indore, Delhi/NCR, Ahmedabad.**Job Description :**\- 6+ years of overall Data Analytics and BI experience\- Experience in Spark, Hive, Scala.\- Build data pipelines for ETL that fetch data from variety of sources such as flat files relational databases and APIs\- Python scripting with focus on data transformation and manipulation libraries such as Pandas and numpy\- Strong knowledge and hands-on experience of SQL (should be able to write advance level SQL queries)\- Good hands-on experience on data visualization tools such as Power BI, Tableau, Looker\- Good understanding and hands-on experience of Data engineering pipeline management tools such as Airflow\- Good Communication skills.",020525913692,"Data Engineering,Business Intelligence,Hive,Power BI,Scala,Data Visualization Tools,Spark,Tableau"
Spark,Cloud Data Engineer- Spark & Databricks,Brighttier Inc,7-15 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-cloud-data-engineer-spark-databricks-brighttier-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-7-to-15-years-270924503642,"Hands-on experience with data platforms like Redshift,Snowflake,Azure Synapse,and BigQueryBachelors degree in Computer Science,Information Technology,or a related fieldExperience in extracting data from SAP or ERP systems is preferredCertifications in cloud platforms (e.g.,AWS Certified Data Analytics,Google Professional Data Engineer,Azure Data Engineer Associate )",270924503642,"Computer science,ERP,SAP,Data modeling,Data quality,Informatica,Apache,Information technology"
Spark,Big data Spark Scala Developers,Diverse Lynx,2-7 Yrs,Not disclosed,Chennai,/job-listings-big-data-spark-scala-developers-diverse-lynx-chennai-2-to-7-years-271223501788,"Performance Optimization:Fine-tune and optimize Spark applications for maximum performance and efficiency . Troubleshoot and resolve performance issues,bottlenecks,and data processing errors . Data Integration:Integrate big data solutions with existing systems and data warehouses .",271223501788,"spark,SCALA,Developer,Data processing,Unit testing,Business intelligence,big data,Analytics"
Spark,Big Data Developer (Python and Spark),MNJ Software,4-6 Yrs,Not disclosed,Remote,/job-listings-big-data-developer-python-and-spark-mnj-software-private-limited-remote-4-to-6-years-101122502454,"4 Years of software development experience in a professional setting with focus on Python,Spark and Big Data Technologies . Ability to effectively interpret technical and business objectives and challenges and articulate robust and sustainable technology solutions .Willingness to learn new technologies and exploit them to their optimal potential",101122502454,"IT services,Computer science,Product engineering,Analytical,Shell scripting,Agile,Vulnerability,Business solutions"
Spark,Data Engineer - (Hadoop/Hive/python/Spark/Scala),Capco,4-8 Yrs,Not disclosed,Bengaluru,/job-listings-data-engineer-hadoop-hive-python-spark-scala-capco-technologies-pvt-ltd-bengaluru-4-to-8-years-140525915039,"**Job TitleSenior Data Engineer/Developer****Number of Positions2****About The Role :**The Senior Data Engineer will be responsible for designing, developing, and maintaining scalable data pipelines and building out new API integrations to support continuing increases in data volume and complexity. They will collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.**Responsibilities:*** Design, construct, install, test and maintain highly scalable data management systems & Data Pipeline.* Ensure systems meet business requirements and industry practices.* Build high-performance algorithms, prototypes, predictive models, and proof of concepts.* Research opportunities for data acquisition and new uses for existing data.* Develop data set processes for data modeling, mining and production.* Integrate new data management technologies and software engineering tools into existing structures.* Create custom software components and analytics applications.* Install and update disaster recovery procedures.* Collaborate with data architects, modelers, and IT team members on project goals.* Provide senior level technical consulting to peer data engineers during data application design and development for highly complex and critical data projects.**Qualifications:*** Bachelor's degree in computer science, Engineering, or related field, or equivalent work experience.* Proven 5-8 years of experienceas a Senior Data Engineer or similar role.* Experience with big data toolsHadoop, Spark, Kafka, Ansible, chef, Terraform, Airflow, and Protobuf RPC etc.* Expert level SQL skills for data manipulation (DML) and validation (DB2).* Experience with data pipeline and workflow management tools.* Experience with object-oriented/object function scripting languagesPython, Java, Go langetc.* Strong problem solving and analytical skills.* Excellent verbal communication skills.* Good interpersonal skills.* Ability to provide technical leadership for the team.",140525915039,"data manipulation,airflow,sql,java,spark,hive,algorithms,dml"
Spark,Data Engineer - (Hadoop/Hive/python/Spark/Scala),Capco,5-8 Yrs,Not disclosed,Bengaluru,/job-listings-data-engineer-hadoop-hive-python-spark-scala-capco-technologies-pvt-ltd-bengaluru-5-to-8-years-210225500136,"Bachelors degree in computer science,Engineering,or related field,or equivalent work experienceProven 5-8 years of experience as a Senior Data Engineer or similar roleExperience with big data tools: Hadoop,Spark,Kafka,Ansible,chef,Terraform,Airflow,and Protobuf RPC etc",210225500136,"Computer science,Data management,Db2,Data modeling,Consulting,Disaster recovery,Business intelligence,Analytics"
Spark,Spark Developer,Appzlogic,0-2 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-spark-developer-appzlogic-mobility-solutions-pvt-ltd-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-0-to-2-years-111124502361,"Proven experience as a Spark Developer or in a similar roleExperience with big data processing frameworks such as HadoopExperience with data storage and retrieval technologies such as HDFS,HBase,Cassandra,or similarExperience with cloud platforms (AWS,Azure,Google Cloud) is a plus",111124502361,"python,performance tuning,scala,data processing,big data technologies,microsoft azure,cloud platforms,data pipeline"
Spark,Spark Developer,Emtec Inc.,5-7 Yrs,Not disclosed,"Pune, Bengaluru",/job-listings-spark-developer-emtec-inc-pune-bengaluru-5-to-7-years-170425504613,"## Spark Developer**Job ID:** Spa-ETP-Pun-1022**Location:** Pune,Bangalore,Other**Company Overview**Bridgenext is a global digital consultancy that helps clients innovate with intention and realize their digital aspirations by creating digital products, experiences, and solutions around what real people need. Our global consulting and delivery teams facilitate highly strategic digital initiatives through digital product engineering, automation, data engineering, and infrastructure modernization services, while elevating brands through digital experience, creative content, and customer data analytics services.Don t just work, thrive. At Bridgenext, you have an opportunity to make a real difference driving tangible business value for clients, while simultaneously propelling your own career growth. Our flexible and inclusive work culture provides you with the autonomy, resources, and opportunities to succeed.We are looking for an Engineer with hands-on Data Engineering experience who will work on the internal and customer-based projects for Bridgenext, someone who cares about the quality of the code and who is passionate about providing the best solution to meet the client s needs and anticipates their future needs based on an understanding of the market.**Must Have Skills:*** Bachelor s degree in Computer Science, Engineering, or a related field.* 5+ years of experience in data engineering, with a strong focus on large-scale data processing using Apache Spark.* Experience in handling large scale data(Terra bytes) of data using Spark* Strong expertise in optimizing Apache Spark jobs on both on-premises (HDFS) and cloud environments (AWS S3).* Experience with Spark resource tuning and performance optimization, including partitioning, caching, and memory management.* Proven experience in migrating data pipelines from on-premises systems (HDFS) to cloud platforms* Experience with Spark SQL query optimization, including working with Catalyst Optimizer.* Hands-on experience with data migration tools and frameworks, especially for moving data from HDFS to S3 (* Strong troubleshooting skills, especially in diagnosing and resolving performance issues in Spark applications and data pipelines.* Experience in Kubernetes is a plus.Apply NowReturn to search",170425504613,"Automation,Data migration,Product engineering,query optimization,Memory management,Consulting,Data processing,Troubleshooting"
Spark,Spark Developer,Emtec Inc.,4-7 Yrs,Not disclosed,"Pune, Bengaluru",/job-listings-spark-developer-emtec-inc-pune-bengaluru-4-to-7-years-061224503583,"Bachelor s degree in Computer Science,Engineering,or a related fieldExperience with Spark resource tuning and performance optimization,including partitioning,caching,and memory management4+ years of experience in data engineering,with a strong focus on large-scale data processing using Apache Spark and AWS",061224503583,"Automation,Product engineering,Data migration,spark,Consulting,Data processing,hdfs,Troubleshooting"
Spark,Spark Developer,Infosys,2-3 Yrs,Not disclosed,Bengaluru,/job-listings-spark-developer-infosys-limited-bengaluru-2-to-3-years-090525922858,"MCA,MSc,Bachelor of Engineering,BBA,BCom . Service LineYou will create requirement specifications from the business needs,define the to-be-processes and detailed functional designs based on requirementsPreferred .INFSYS-NAUKRI-210683. Work Experience",090525922858,"hive,data processing,spark,hadoop,big data,python,scala,oozie"
Spark,Spark Developer,Infosys,3-5 Yrs,Not disclosed,Bengaluru,/job-listings-spark-developer-infosys-limited-bengaluru-3-to-5-years-090525922843,"MCA,MSc,Bachelor of Engineering,BBA,BCom,BSc . Service LinePreferred .INFSYS-NAUKRI-210690. Work ExperienceExperience with Spark SQL and DataFramesGood exposure to Big Data architectures and good understanding of Big Data eco systemExperience with some framework building experience on HadoopGood with DB knowledge with SQL tuning experience",090525922843,"big data technologies,spark,hadoop,big data,python,hive,scala,sql tuning"
Spark,Lead Data Engineer - Spark/Python,Unicon Connectors,5-7 Yrs,Not disclosed,Pune,/job-listings-lead-data-engineer-spark-python-unico-connect-private-limited-pune-5-to-7-years-160525926672,"Have a relevant degree such as Bachelors and Masters Degree in Computer Science,Engineering,Statistics,Education,Technical,Information Technology,Information Systems,Mathematics,Computer Engineering,Management.",160525926672,"Python,Data Engineering,Hadoop,Big Data,HDFS,Spark,Distributed Systems,Engineering"
Spark,"Data Engineer (Scala, Spark)",Rarr Technologies,5-9 Yrs,Not disclosed,"Noida, Hyderabad, Pune",/job-listings-data-engineer-scala-spark-rarr-technologies-noida-hyderabad-pune-5-to-9-years-270325500357,"Bigdata Technologies - Lead Data Engineer (8+ Years of overall experience in Data Engineering across Enterprise Data Platforms,Data Hub,Lambda Architecture & Cloud technologies) Primary - Spark including streaming,Scala,Hadoop,Hbase,Kafka,Delta (preferably CDP),SQLKnowledge / Experience of Azure Cloud Secondary / Good to have - Elastic Search,Data bricks,ADF,R,Python",270325500357,"Architecture,spark,Delta,SCALA,Cloud,Hadoop,AWS,SQL"
Airflow,Associate - Data Engineer,Deutsche Bank,1-5 Yrs,Not disclosed,Pune,/job-listings-associate-data-engineer-deutsche-bank-ag-pune-1-to-5-years-080525914789,"When you see a process running with high manual effort,youll fix it to run automated,optimizing not only our operating model,but also giving yourself more time for developmentPreferred Skills .Your skills and experience .Experience working in a fast-paced and Agile work environmentExperience inDataflow (Apache Beam)/Cloud Functions / Cloud Run",080525914789,"continuous integration,python,ci/cd,sql,nosql databases,beam,github,data analytics"
Airflow,Airflow Data Engineer,Avivys Consulting Services,2-6 Yrs,Not disclosed,Pune,/job-listings-airflow-data-engineer-avivys-cunsulting-services-pune-2-to-6-years-130125507119,"Create reusable components and efficient DAGs (Directed Acyclic Graphs). Workflow Automation: Build and automate end-to-end data pipelines for batch and real-timeExperience: 7-8 years of professional experience in data engineering or softwareExperience with Airflow x and its features such as dynamicExperience with libraries like Pandas,NumPy,etc. .",130125507119,"Automation,Version control,Coding,Consulting,MySQL,Machine learning,Data quality,Troubleshooting"
Airflow,Big Data Engineer,Capco,5-8 Yrs,Not disclosed,Pune,/job-listings-big-data-engineer-capco-technologies-pvt-ltd-pune-5-to-8-years-300525930599,"Job Title**Big Data Engineer**About UsCapco, a Wipro company, is a global technology and management consulting firm. Awarded with Consultancy of the year in the British Bank Award and has been ranked Top 100 Best Companies for Women in India 2022 by Avtar & Seramount . With our presence across 32 cities across globe, we support 100+ clients across banking, financial and Energy sectors. We are recognized for our deep transformation execution and delivery.WHY JOIN CAPCOYou will work on engaging projects with the largest international and local banks, insurance companies, payment service providers and other key players in the industry. The projects that will transform the financial services industry.MAKE AN IMPACTInnovative thinking, delivery excellence and thought leadership to help our clients transform their business. Together with our clients and industry partners, we deliver disruptive work that is changing energy and financial services.#BEYOURSELFATWORKCapco has a tolerant, open culture that values diversity, inclusivity, and creativity.CAREER ADVANCEMENTWith no forced hierarchy at Capco, everyone has the opportunity to grow as we grow, taking their career into their own hands.DIVERSITY & INCLUSIONWe believe that diversity of people and perspective gives us a competitive advantage.MAKE AN IMPACT**Job TitleBig Data Engineer****:**The Senior Data Engineer will be responsible for designing, developing, and maintaining scalable data pipelines and building out new API integrations to support continuing increases in data volume and complexity. They will collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.**Responsibilities:*** Design, construct, install, test and maintain highly scalable data management systems & Data Pipeline.* Ensure systems meet business requirements and industry practices.* Build high-performance algorithms, prototypes, predictive models, and proof of concepts.* Research opportunities for data acquisition and new uses for existing data.* Develop data set processes for data modeling, mining and production.* Integrate new data management technologies and software engineering tools into existing structures.* Create custom software components and analytics applications.* Install and update disaster recovery procedures.* Collaborate with data architects, modelers, and IT team members on project goals.* Provide senior level technical consulting to peer data engineers during data application design and development for highly complex and critical data projects.**Qualifications:*** Bachelor's degree in Computer Science, Engineering, or related field, or equivalent work experience.* Proven 5-8 years of experience as a Senior Data Engineer or similar role.* Experience with big data toolsPyspark, Hadoop, Spark, Kafka, Ansible, chef, Terraform, Airflow, and Protobuf RPC etc..* Expert level SQL skills for data manipulation (DML) and validation (DB2).* Experience with data pipeline and workflow management tools.* Experience with object-oriented/object function scripting languagesPython, Java, Go lang etc.* Strong problem solving and analytical skills.* Excellent verbal communication skills.* Good interpersonal skills.* Ability to provide technical leadership for the team.",300525930599,"data manipulation,sql,java,spark,hadoop,algorithms,dml,data management"
Airflow,Big Data Engineer,Capco,4-7 Yrs,Not disclosed,Pune,/job-listings-big-data-engineer-capco-technologies-pvt-ltd-pune-4-to-7-years-140525914982,"Job Title**Big Data Engineer**About Us“Capco, a Wipro company, is a global technology and management consulting firm. Awarded with Consultancy of the year in the British Bank Award and has been ranked Top 100 Best Companies for Women in India 2022 by Avtar & Seramount. With our presence across 32 cities across globe, we support 100+ clients acrossbanking, financial and Energy sectors. We are recognized for our deep transformation execution and delivery.WHY JOIN CAPCO?You will work on engaging projects with the largest international and local banks, insurance companies, payment service providers and other key players in the industry. The projects that will transform the financial services industry.MAKE AN IMPACTInnovative thinking, delivery excellence and thought leadership to help our clients transform their business. Together with our clients and industry partners, we deliver disruptive work that is changing energy and financial services.#BEYOURSELFATWORKCapco has a tolerant, open culture that values diversity, inclusivity, and creativity.CAREER ADVANCEMENTWith no forced hierarchy at Capco, everyone has the opportunity to grow as we grow, taking their career into their own hands.DIVERSITY & INCLUSIONWe believe that diversity of people and perspective gives us a competitive advantage.MAKE AN IMPACT**Job TitleBig Data Engineer****About The Role :**The Senior Data Engineer will be responsible for designing, developing, and maintaining scalable data pipelines and building out new API integrations to support continuing increases in data volume and complexity. They will collaborate with analytics and business teams to improve data models that feed business intelligence tools, increasing data accessibility and fostering data-driven decision making across the organization.**Responsibilities:*** Design, construct, install, test and maintain highly scalable data management systems & Data Pipeline.* Ensure systems meet business requirements and industry practices.* Build high-performance algorithms, prototypes, predictive models, and proof of concepts.* Research opportunities for data acquisition and new uses for existing data.* Develop data set processes for data modeling, mining and production.* Integrate new data management technologies and software engineering tools into existing structures.* Create custom software components and analytics applications.* Install and update disaster recovery procedures.* Collaborate with data architects, modelers, and IT team members on project goals.* Provide senior level technical consulting to peer data engineers during data application design and development for highly complex and critical data projects.**Qualifications:*** Bachelor's degree in Computer Science, Engineering, or related field, or equivalent work experience.* Proven 5-8 years of experienceas a Senior Data Engineer or similar role.* Experience with big data toolsPyspark, Hadoop, Spark, Kafka, Ansible, chef, Terraform, Airflow, and Protobuf RPC etc..* Expert level SQL skills for data manipulation (DML) and validation (DB2).* Experience with data pipeline and workflow management tools.* Experience with object-oriented/object function scripting languagesPython, Java, Go langetc.* Strong problem solving and analytical skills.* Excellent verbal communication skills.* Good interpersonal skills.* Ability to provide technical leadership for the team.",140525914982,"data manipulation,sql,java,spark,hadoop,algorithms,dml,data management"
Airflow,Genpact Hiring For GCP Data Engineer,Genpact,6-11 Yrs,Not disclosed,"Hybrid - Hyderabad/Secunderabad, Bangalore/Bengaluru, Delhi / NCR",/job-listings-genpact-hiring-for-gcp-data-engineer-genpact-hyderabad-secunderabad-bangalore-bengaluru-delhi-ncr-6-to-11-years-200525020310,"Minimum Qualifications / Skills. Bachelors or Masters degree in Computer Science,Engineering,or a related field. . 10+ years of progressive experience in data engineering roles,with a strong focus on cloud technologies.Experience with machine learning workflows and MLOps on GCP (e.g.,Vertex AI)Preferred Qualifications/ Skills",200525020310,"Airflow,gcp data engineer,Bigquery,Data Flow,Gcp Cloud,cloud composer,ETL,SQL"
Airflow,Gcp Data Engineer,Xebia It Architects,5-10 Yrs,Not disclosed,"Hybrid - Hyderabad, Chennai, Bengaluru",/job-listings-gcp-data-engineer-xebia-it-architects-hyderabad-chennai-bengaluru-5-to-10-years-270525021298,"Job Type: Full TimeRequired Experience: . 5+ years in Data Engineering with strong data architecture experience. Hands-on expertise in Databricks,Airflow,BigQuery,and PySpark .Only Immediate Joiners or Candidates with Max 30 Days Notice Period Will Be ConsideredExperience: 5+ Years",270525021298,"GCP,Airflow,Pyspark,Pubsub,Bigquery,Data Flow,Dataproc,Spark"
Airflow,"Corporate Bank Technology-Commercial Banking-Senior Data Engineer,AVP",Deutsche Bank,7-12 Yrs,Not disclosed,Pune,/job-listings-corporate-bank-technology-commercial-banking-senior-data-engineer-avp-deutsche-bank-ag-pune-7-to-12-years-020525902374,"Bachelors degree in Computer Science,Data Science,or related field,or equivalent work experienceStrong experience with Cloud,Terraform,and GitHub ActionsYour skills and experienceProven experience as a Data Engineer or Backend Engineer or similar role",020525902374,"Commercial Banking,Java,Spring Boot,Dataform,SQL,Apache Airflow,SQL queries,GitHub Actions"
Airflow,GCP Data Engineer,Fractal Analytics,8-13 Yrs,Not disclosed,"Hybrid - Pune, Bengaluru, Delhi / NCR",/job-listings-gcp-data-engineer-fractal-analytics-pune-bengaluru-delhi-ncr-8-to-13-years-041224012799,"Develop and manage batch and real-time data processing solutionsAbility to manage large datasets efficiently and design solutions that scale with growing data volumes. Education and Certifications: . A bachelors or masters degree in Computer Science,Information Technology,Data Science,or a related fieldRequired Skills and Qualifications: .Preferred Skills: .",041224012799,"GCP,Data Flow,Cloud Storage,Big Query,Dataproc,Cloud,Flow,Data"
Airflow,GCP Senior Data Engineer,Xebia It Architects,5-10 Yrs,Not disclosed,"Hybrid - Hyderabad, Chennai, Bengaluru",/job-listings-gcp-senior-data-engineer-xebia-it-architects-hyderabad-chennai-bengaluru-5-to-10-years-170325001226,"Shift: 2 PM 11 PM7-8 years of experience in data engineering,architecture,and pipeline development . . Strong knowledge of GCP,Databricks,PySpark,and BigQuery .Experience with Orchestration tools like Airflow,Dagster,or GCP equivalents . . Understanding of Data Lake table formats (Delta,Iceberg,etc.).",170325001226,"GCP,Airflow,Pyspark,Spark,Data Bricks,Python,Data,Bricks"
Airflow,GCP DATA ENGINEER,Capgemini,6-11 Yrs,Not disclosed,Mumbai,/job-listings-gcp-data-engineer-capgemini-technology-services-india-limited-mumbai-6-to-11-years-200525924288,"Very good collaboration skills and ability to interact with multi-cultural and multi-functional teams spread across geographiesYour Role . As a senior software engineer with Capgemini,you should have 4 + years of experience in GCP Data Engineer with strong project track recordVery good Understanding of current work and the tools and technologies being used",200525924288,"pyspark,bigquery,presentation skills,customer care,decision making,hive,scala,apache pig"
Airflow,"Senior Data Engineer - Python, Snowflake",Relanto Global,3-6 Yrs,Not disclosed,"Hyderabad, Pune, Bengaluru",/job-listings-senior-data-engineer-python-snowflake-relanto-global-private-limited-hyderabad-pune-bengaluru-3-to-6-years-300425916486,"The ideal candidate should have hands-on experience with Apache Airflow,DBT,PySpark,SparkSQL,Snowflake,and Python,along with strong knowledge of data security,governance,and CI / CD practicesRequired Skills & Qualifications: . 3-6 years of experience in Data EngineeringStrong experience with ETL orchestration tools like Apache Airflow and DBT",300425916486,"Python,Apache Airflow,Git,PySpark,GitHub,Snowflake,SparkSQL,CI/CD"
Airflow,"Strategic Data Archive Onboarding Engineer, AS",Deutsche Bank,6-8 Yrs,Not disclosed,Pune,/job-listings-strategic-data-archive-onboarding-engineer-as-deutsche-bank-ag-pune-6-to-8-years-300525930464,"Bachelors Degree from an accredited college or university desirableMinimum 4 years experience implementing IT solutions in a global financial institutionComfortable with technology (e.g.,SQL,FTP,XML,JSON) and a desire and ability to learn new skills as required (e.g.,Fabric,Kubernetes,Kafka,Avro,Ansible)Must be an expert in SQL and have Python programming experience",300525930464,"kubernetes,it solutions,sql,ansible,python,hive,metadata,scala"
Airflow,Enterprise Architect - Airflow & Data Engineering,Quest Global,15-20 Yrs,Not disclosed,Hyderabad,/job-listings-enterprise-architect-airflow-data-engineering-quest-global-hyderabad-15-to-20-years-160425014734,Specific Areas of experience: . IoT ExperienceMQTT. Data base experience. Work Experience .IoT Experience,160425014734,"Airflow,Etl Pipelines,Data Engineering,Big Data,Spark,Artificial Intelligence,Machine Learning,Pipeline"
Airflow,Gcp Data Engineer,TELUS International,5-10 Yrs,Not disclosed,Remote,/job-listings-gcp-data-engineer-telus-international-noida-5-to-10-years-310525017257,"Willingness to work in the afternoon shift from 3 PM to 12 AM ISTLeverage your expertise in various GCP technologies,including BigQuery,Dataproc,GCP Workflows,Dataflow,Cloud Scheduler,Secret Manager,Batch,Cloud Logging,Cloud SDK,Google Cloud Storage,IAM,and Vertex AI,to enhance data warehousing solutionsProven experience in migrating data pipelines from SAS to GCP technologies",310525017257,"Bigquery,ETL,Python,SQL,Airflow,Cloud Storage,Pubsub,Cloud"
Airflow,Immediate Hiring Data Engineer - DBT & Apache Airflow,BSC Services,6-11 Yrs,Not disclosed,Hybrid - Pune,/job-listings-immediate-hiring-data-engineer-dbt-apache-airflow-bsc-services-pune-6-to-11-years-250425027108,"**Project Role Description:** As data engineer the person will be responsible for data transformation & Migration in **Amazon RedShift using Apache Airflow, Data Build Tool and Cosmos.****Work location:** Pune/Remote.Graduate or Post-Graduate in Computer Science/ Information Technology/Engineering.Joining Timelines: **Immediate joiner Only**.**Job Requirements:****Must Have Skills:*** 6 to 11 years IT Experience in data transformation in **Amazon RedShift- Datawarehouse** using **Apache Airflow, Data Build Tool (DBT) and Cosmos**.* Hands-on experience working in complex data warehouse implementations.* Expert in Advance **SQL.*** **Expert in understanding Data Models is Must.*** Hands on **experience parsing responses generated by API's (REST/XML/JSON)**.* Experience with Client interaction is must for demonstrating multiple data solutions.* The Data Engineer will be responsible for designing, developing, testing and maintaining data pipelines.* Experience of **dbt (Data Build Tool)** for data transformation is **Must**.* Experience in developing, scheduling & monitoring workflow orchestration using **Apache Airflow is MUST.*** Experienced in **Astro & Cosmos library is MUST**.* Experience in construction of the **DAG** in Airflow.* Experience of DevOps: **BitBucket** or Experience of Github /Gitlab* Extensive experience in dimensional data modelling includes complex entity relationships and historical data entities.* Implementation of data cleansing and data quality features in ETL pipelines.* Implementation of data streaming solutions from different sources for data migration & transformation.* Experience in **SQL and Performance Tuning**.**Soft Skills:*** Hands-on analytical, problem solving and debugging skills.* Ability to work under pressure.* The person Should be flexible to work independently or in a team.* Excellent communication skills and ability to present results in a concise manner to technical & non-technical stakeholders.* Curiosity and eagerness to learn & work in a collaborative and open team culture.**_Contact details_** :Email ID : **Contact@beyondscs.com**Number : **07066756612**",250425027108,"Apache Airflow,DBT,Advance SQL,Cosmos,Python,Data Transformation,Data Engineering,Data Migration"
Airflow,Senior Data Engineer,Quaxigma,5-10 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-senior-data-engineer-quaxigma-it-solutions-private-limited-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-5-to-10-years-261224501168,"Experience with solutioning on AWS infrastructure using services like AWS S3,Lambda,EMR,Redshift (or Snowflake) .Develop architecture required to return data to data warehouse for front-end product utilization . Curate data models in the data warehouse to be used by front-end advanced analytics designers .Skills / Experience required",261224501168,"hive,scala,amazon redshift,emr,t-sql,sql,spark streaming,spark"
Airflow,Senior Data Engineering Consultant,Optum,5-9 Yrs,Not disclosed,Bengaluru,/job-listings-senior-data-engineering-consultant-optum-global-solutions-india-private-limited-bengaluru-5-to-9-years-270525929733,"As a Tech Lead,the candidate should be able to work as an individual contributor as well as people manager. Be able to work on data pipelines and databases. Be able to work on data intensive applications or systems. Be able to lead the team and have to soft skills for the same. Be able to review code,design and mentor the team members.",270525929733,"airflow,pyspark,sql,spark,hadoop,python,data analysis,data analytics"
Airflow,"Senior Data Engineer (AWS, Airflow, DBT & Cloud Data Pipelines)",Synechron,3-7 Yrs,Not disclosed,Bengaluru,/job-listings-senior-data-engineer-aws-airflow-dbt-cloud-data-pipelines-synechron-technologies-pvt-ltd-bengaluru-3-to-7-years-270525928954,"**Job Summary:** Synechron is seeking an experienced Senior Data Engineer with expertise in AWS, Apache Airflow, and DBT to design and implement scalable, reliable data pipelines. The role involves collaborating with data teams and business stakeholders to develop data solutions that enable actionable insights and support organizational decision-making. The ideal candidate will bring data engineering experience, demonstrating strong technical skills, strategic thinking, and the ability to work in a fast-paced, evolving environment.**Software Requirements:*****Required:*** Strong proficiency in AWS services including S3, Redshift, Lambda, and Glue, with proven hands-on experience* Expertise in Apache Airflow for workflow orchestration and pipeline management* Extensive experience with DBT for data transformation and modeling* Solid knowledge of SQL for data querying and manipulation***Preferred:*** Familiarity with Hadoop, Spark, or other big data technologies* Experience with NoSQL databases (e.g., DynamoDB, Cassandra)* Knowledge of data governance and security best practices within cloud environments**Overall Responsibilities:*** Lead the design, development, and maintenance of scalable and efficient data pipelines and workflows utilizing AWS, Airflow, and DBT* Collaborate with data scientists, analysts, and business teams to gather requirements and translate them into technical solutions* Optimize Extract, Transform, Load (ETL) processes to enhance data quality, integrity, and timeliness* Monitor pipeline performance, troubleshoot issues, and implement improvements to ensure operational excellence* Enforce data management, governance, and security protocols across all data flows* Mentor junior data engineers and promote best practices within the team* Stay current with emerging data technologies and industry trends, recommending innovations for the data ecosystem**Technical Skills (By Category):*****Programming Languages:*** _Essential:_ SQL, Python (preferred for scripting and automation)* _Preferred:_ Spark, Scala, Java (for big data integration)***Databases/Data Management:*** Extensive experience with data warehousing (Redshift, Snowflake, or similar) and relational databases (MySQL, PostgreSQL)* Familiarity with NoSQL databases such as DynamoDB or Cassandra is a plus***Cloud Technologies:*** AWS cloud platform, leveraging services like S3, Lambda, Glue, Redshift, and IAM security features***Frameworks and Libraries:*** Apache Airflow, dbt, and related data orchestration and transformation tools***Development Tools and Methodologies:*** Git, Jenkins, CI/CD pipelines, Agile/Scrum environment experience***Security Protocols:*** Knowledge of data encryption, access control, and compliance standards in cloud data engineering**Experience Requirements:*** At least 8 years of professional experience in data engineering or related roles with a focus on cloud ecosystems and big data pipelines* Demonstrated experience designing and managing end-to-end data workflows in AWS environments* Proven success in collaborating with cross-functional teams and translating business requirements into technical solutions* Prior experience mentoring junior engineers and leading data projects is highly desirable**Day-to-Day Activities:*** Develop, deploy, and monitor scalable data pipelines using AWS, Airflow, and DBT* Collaborate regularly with data scientists, analysts, and business stakeholders to refine data requirements and deliver impactful solutions* Troubleshoot production data pipeline issues to resolve data quality or performance bottlenecks* Conduct code reviews, optimize existing workflows, and implement automation to improve efficiency* Document data architecture, pipelines, and governance practices for knowledge sharing and compliance* Keep abreast of emerging data tools and industry best practices, proposing enhancements to existing systems**Qualifications:*** Bachelor’s degree in Computer Science, Data Science, Engineering, or related field; Master’s degree preferred* Professional certifications such as AWS Certified Data Analytics – Specialty or related credentials are advantageous* Commitment to continuous professional development and staying current with industry trends**Professional Competencies:*** Strong analytical, problem-solving, and critical thinking skills* Excellent communication abilities to effectively liaise with technical and business teams* Proven leadership in mentoring team members and managing project deliverables* Ability to work independently, prioritize tasks, and adapt to changing business needs* Innovative mindset focused on scalable, efficient, and sustainable data solutions__",270525928954,"airflow,data warehousing,relational databases,sql,aws,continuous integration,python,aws iam"
Airflow,GCP Senior data Engineer,Xebia It Architects,10-15 Yrs,Not disclosed,"Hybrid - Bhopal, Pune, Gurugram",/job-listings-gcp-senior-data-engineer-xebia-it-architects-bhopal-pune-gurugram-10-to-15-years-270525024954,"**Job Title:** Senior Data Engineer GCP | Big Data | Airflow | dbt**Company: Xebia****Location:** All Xebia locations**Experience:** 10+ Years**Employment Type:** Full Time**Notice Period:** Immediate to Max 30 Days Only**Job Summary**Join the digital transformation journey of one of the world’s most iconic global retail brands! As a **Senior Data Engineer** , you’ll be part of a dynamic Digital Technology organization, helping build modern, scalable, and reliable data products to power business decisions across the Americas. You'll work in the Operations Data Domain, focused on ingesting, processing, and optimizing high-volume data pipelines using **Google Cloud Platform (GCP)** and other modern tools.**Key Responsibilities*** Design, develop, and maintain highly scalable big data pipelines (batch & streaming)* Collaborate with cross-functional teams to understand data needs and deliver efficient solutions* Architect robust data solutions using GCP-native services (BigQuery, Pub/Sub, Cloud Functions, etc.)* Build and manage modern Data Lake/Lakehouse platforms* Create frameworks and reusable components for scalable ingestion and processing* Implement data governance, security, and ensure regulatory compliance* Mentor junior engineers and lead an offshore team of 8+ engineers* Monitor pipeline performance, troubleshoot bottlenecks, and ensure data quality* Engage in code reviews, CI/CD deployments, and agile product releases* Contribute to internal best practices and engineering standards**Must-Have Skills & Qualifications*** 8+ years in data engineering with strong hands-on experience in production-grade pipelines* Expertise in **GCP Data Services** – BigQuery, Vertex AI, Pub/Sub, etc.* Proficiency in **dbt (Data Build Tool)** for data transformation* Strong programming skills in **Python, Java, or Scala*** Advanced SQL & NoSQL knowledge* Experience with **Apache Airflow** for orchestration* Hands-on with **Git, GitHub Actions** , Jenkins for CI/CD* Solid understanding of data warehousing (BigQuery, Snowflake, Redshift)* Exposure to tools like **Hadoop, Spark, Kafka** , Databricks (nice to have)* Familiarity with BI tools like **Tableau, Power BI, or Looker** (optional)* Strong leadership qualities to manage offshore engineering teams* Excellent communication skills and stakeholder management experience**Preferred Education*** Bachelor’s or Master’s degree in Computer Science, Engineering, Mathematics, or a related field**Notice Period Requirement**Only **Immediate Joiners** or candidates with **Max 30 Days Notice Period** will be considered.**How to Apply**If you are passionate about solving real-world data problems and want to be part of a global data-driven transformation, apply now by sending your resume to **vijay.s@xebia.com** with the subject line: **""Sr Data Engineer Application – [Your Name]""**Kindly include the following details in your email:* Full Name* Total Experience* Current CTC* Expected CTC* Current Location* Preferred Location* Notice Period / Last Working Day* Key SkillsPlease **do not apply** if you are currently in process with any other role at Xebia or have recently interviewed.",270525024954,"GCP,Cloud Sql,Airflow,Pubsub,Pyspark,Bigquery,Data Flow,Dataproc"
Airflow,GCP  Data Engineer,Techominds,7-12 Yrs,Not disclosed,"Hybrid - Hyderabad, Chennai, Bengaluru",/job-listings-gcp-data-engineer-techominds-hyderabad-chennai-bengaluru-7-to-12-years-280525025066,"Required Skills: Python,ETL,SQL,GCP,Bigquery,Pub / Sub,Airflow. . Good to Have: DBT,Data mesh. Job Title: Senior GCP Engineer Data Mesh & Data Product Specialist . We are hiring a Senior GCP Developer to join our high-performance data engineering team",280525025066,"GCP,Python,Airflow,Pubsub,Bigquery,SQL,data mesh,Data"
Airflow,Technical Specialist - Data Engineer,Deutsche Bank,2-6 Yrs,Not disclosed,Pune,/job-listings-technical-specialist-data-engineer-deutsche-bank-ag-pune-2-to-6-years-010525908470,"Bachelor of Science degree from an accredited college or university with a concentration in Computer Science or Software Engineering (or equivalent) with a minor in Finance,Mathematics or EngineeringSoftware test findings must be resolvedProficient communication skillsYour skills and experience . General Skills .Relevant Financial Services experience",010525908470,"scala,java,apache,spark,gcp,beam,sql,data modeling"
Airflow,Corporate Bank Technology  Commercial Banking  Data Engineer,Deutsche Bank,2-7 Yrs,Not disclosed,Pune,/job-listings-corporate-bank-technology-commercial-banking-data-engineer-deutsche-bank-ag-pune-2-to-7-years-010525907875,"Your skills and experience . Bachelors degree in Computer Science,Data Science,or related field,or equivalent work experienceStrong experience with Cloud,Terraform,and GitHub ActionsProficiency in SQL and Java and / or Python,experience with tools and frameworks like Apache Beam,Spring Boot and Apache Airflow",010525907875,"python,github,sql,java,terraform,hive,continuous integration,beam"
Airflow,GCP Data Engineer | 6-12 yrs | Largest MNC !!,SP Staffing,6-11 Yrs,15-30 Lacs PA,"Hyderabad, Pune, Bengaluru",/job-listings-gcp-data-engineer-6-12-yrs-largest-mnc-sp-staffing-hyderabad-pune-bengaluru-6-to-11-years-300525031162,"**Warm welcome from SP Staffing Services!****Reaching out to you regarding permanent opportunity !!****Job Description:****Exp: 6-12 yrs****Location:** **Hyderabad/Bangalore/Pune/Delhi****Skill: GCP Data Engineer****\- Proficiency in programming languages: Python****\- Expertise in data processing frameworks: Apache Beam (Data Flow), Kafka,****\- Hands-on experience with GCP services: Big Query, Dataflow, Composer, Spanner****\- Knowledge of data modeling and database design****\- Experience in ETL (Extract, Transform, Load) processes****\- Familiarity with cloud storage solutions****\- Strong problem-solving abilities in data engineering challenges****\- Understanding of data security and scalability****\- Proficiency in relevant tools like Apache Airflow****Interested can share your resume to sangeetha.spstaffing@gmail.com with below inline details.****Full Name as per PAN:****Mobile No:****Alt No/ Whatsapp No:****Total Exp:****Relevant Exp in GCP:****Rel Exp in Big Query:****Rel Exp in Composer:****Rel Exp in Python:****Current CTC:****Expected CTC:****Notice Period (Official):****Notice Period (Negotiable)/Reason:****Date of Birth:****PAN number:****Reason for Job Change:****Offer in Pipeline (Current Status):****Availability for virtual interview on weekdays between 10 AM- 4 PM(plz mention time):****Current Res Location:****Preferred Job Location:****Whether educational % in 10th std, 12th std, UG is all above 50%?****Do you have any gaps in between your education or Career?****If having gap, please mention the duration in months/year:**",300525031162,"Composer,GCP,Bigquery,Python,Data Flow,Google Cloud,Composing,Data"
Airflow,Data Engineer,Tangibleheed Infotech,1-3 Yrs,Not disclosed,Pune,/job-listings-data-engineer-tangibleheed-infotech-pune-1-to-3-years-240425500913,Tangibleheed Infotech is looking for Data Engineer to join our dynamic team and embark on a rewarding career journey.1. Liaising with coworkers and clients to elucidate the requirements for each task.2. Conceptualizing and generating infrastructure that allows big data to be accessed and analyzed.3. Reformulating existing frameworks to optimize their functioning.4. Testing such structures to ensure that they are fit for use.5. Preparing raw data for manipulation by data scientists.6. Detecting and correcting errors in your work.7. Ensuring that your work remains backed up and readily accessible to relevant coworkers.8. Remaining up-to-date with industry standards and technological advancements that will improve the quality of your outputs.,240425500913,"hive,cloudera,python,data analysis,scala,oozie,airflow,data warehousing"
Airflow,Data Engineer,NR Consulting,8-13 Yrs,15-30 Lacs PA,"Pune, Chennai, Bengaluru",/job-listings-data-engineer-nr-consulting-pune-chennai-bengaluru-8-to-13-years-300525923385,Working with integration of structured data & Semi-Structure data sets . Work on Performance Tuning and cost optimization . Work on implementing CDC or SCD type 2 . Design and build solutions for near real-time stream as well as batch processingDesign and build solutions for near real-time stream processing as well as batch processing,300525923385,"Snowflake,Data Build Tool,SQL,Airflow,Unix,Pyspark,GIT,DWH"
Airflow,Senior Data Analytics Engineer,Randstad,5-7 Yrs,Not disclosed,Hyderabad,/job-listings-senior-data-analytics-engineer-randstad-hyderabad-5-to-7-years-210525029950,"Bachelors degree in Computer Science,Information Technology,or a related fieldData engineering certification and basic knowledge of AI / ML fundamentals are a plusRequired Skills & Experience . Hands-on experience with Google Cloud Platform (GCP) and Google BigQueryProven experience in designing and implementing ETL pipelines and data transformation flows",210525029950,"Python,Airflow,Google Cloud Platforms,ETL,SQL,Cloud,Data analytics,Senior"
Airflow,GCP Data Engineer,Evnek,5-7 Yrs,Not disclosed,"Mumbai, Delhi / NCR, Bengaluru",/job-listings-gcp-data-engineer-evnek-mumbai-delhi-ncr-bengaluru-5-to-7-years-220525934793,"Experience with NoSQL databases such as Firestore,DynamoDB,or MongoDB is required,along with proficiency in data modeling and warehousing solutions like BigQuery (preferred),Redshift,or Snowflake.The ideal candidate must have strong SQL expertise,including complex joins,stored procedures,and certificate-auth-based queries",220525934793,"SQL,NoSQL,GCP,Data Warehousing,ETL,Airflow,LookerML,BigQuery"
Airflow,Data Engineer-Data Platforms-AWS,IBM,2-6 Yrs,Not disclosed,Pune,/job-listings-data-engineer-data-platforms-aws-ibm-india-pvt-limited-pune-2-to-6-years-120525912959,"* Design, develop, and manage our data infrastructure on AWS, with a focus on data warehousing solutions.* Write efficient, complex SQL queries for data extraction, transformation, and loading.* Utilize DBT for data modelling and transformation.* Use Python for data engineering tasks, demonstrating strong work experience in this area.* Implement scheduling tools like Airflow, Control M, or shell scripting to automate data processes and workflows. Participate in an Agile environment, adapting quickly to changing priorities and requirementsRequired educationBachelor's DegreePreferred educationMaster's DegreeRequired technical and professional expertise* Proven expertise in AWS technologies, with a strong understanding of AWS services. Experience in Redshift is optional* Experience in data warehousing with a solid grasp of SQL, including ability to write complex queries.* Proficiency in Python, demonstrating good work experience in data engineering tasks.* Familiarity with scheduling tools like Airflow, Control M, or shell scripting.* Excellent communication skills, willing attitude towards learningPreferred technical and professional experience* Knowledge of DBT for data modelling and transformation is a plus.* Experience with PySpark or Spark is highly desirable.* Familiarity with DevOps, CI/CD, and Airflow is beneficial.Experience in Agile environments is a nice-to-have",120525912959,"python,aws iam,aws technologies,sql,aws,continuous integration,sql queries,amazon redshift"
Airflow,17th May Face To Face Interview - GCP Data Engineer - BLR & Chennai,Wipro,5-10 Yrs,Not disclosed,Hybrid - Bengaluru,/job-listings-17th-may-face-to-face-interview-gcp-data-engineer-blr-chennai-wipro-bengaluru-5-to-10-years-150525014061,"5+ Years of experience - GCP (all services needed for Big Data pipelines like BigQuery,DataFlow,Pub / Sub,BigTable,Data Fusion,DataProc,Cloud Composer,Cloud SQL,Compute Engine,Cloud Functions,App Engine),CI / CD (experience with Deployment pipelines)",150525014061,"Pyspark,GCP,Cicd Pipeline,Data Flow,Python,Airflow,Pubsub,Bigtable"
Airflow,"Senior Data Engineer(GCP, Python)",S&P Global Market Intelligence,5-10 Yrs,Not disclosed,Gurugram,/job-listings-senior-data-engineer-gcp-python-sp-capital-iq-india-pvt-ltd-gurugram-5-to-10-years-140525921365,"locationsGurgaon, Haryanaposted onPosted 6 Days Agotime left to applyEnd DateJune 6, 2025 (23 days left to apply)job requisition id314204******About the Role:****Grade Level (for internal use):**10**S &P; Global Mobility****The****Role:** Senior Data Engineer**Department overview**Automotive Insights at S&P; Mobility, leverages technology and data science to provide unique insights, forecasts and advisory services spanning every major market and the entire automotive value chainfrom product planning to marketing, sales and the aftermarket.We provide the most comprehensive data spanning the entire automotive lifecyclepast, present and future. With over 100 years of history, unmatched credentials, and the largest base of customers than any other provider, we are the industry benchmark for clients around the world, helping them make informed decisions to capitalize on opportunity and avoid risk.Our solutions are used by nearly every major OEM, 90% of the top 100 tier one suppliers, media agencies, governments, insurance companies, and financial stakeholders to provide actionable insights that enable better decisions and better results.**Position summary**S&P; Global is seeking an experienced and driven Senior data Engineer who is passionate about delivering high-value, high-impact solutions to the worlds most demanding, high-profile clients. The ideal candidate must have at least**5 years** of experience in developing and deploying data pipelines on**Google Cloud Platform (GCP).** They should be passionate about building high-quality, reusable pipelines using cutting-edge technologies. This role involves designing, building, and maintaining scalable data pipelines, optimizing workflows, and ensuring data integrity across multiple systems. The candidate will collaborate with data scientists, analysts, and software engineers to develop robust and efficient data solutions.**Responsibilities*** Design, develop, and maintain scalable ETL/ELT pipelines.* Optimize and automate data ingestion, transformation, and storage processes.* Work with structured and unstructured data sources, ensuring data quality and consistency.* Develop and maintain data models, warehouses, and databases.* Collaborate with cross-functional teams to support data-driven decision-making.* Ensure data security, privacy, and compliance with industry standards.* Troubleshoot and resolve data-related issues in a timely manner.* Monitor and improve system performance, reliability, and scalability.* Stay up-to-date with emerging data technologies and recommend improvements to our data architecture and engineering practices.**What you will need:*** Strong programming skills using python.* 5+ years of experience in data engineering, ETL development, or a related role.* Proficiency in SQL and experience with relational (PostgreSQL, MySQL, etc.) and NoSQL (DynamoDB, MongoDB etc) databases.* **Proficiency building data pipelines in Google cloud platform(GCP) using services like DataFlow, Cloud Batch, BigQuery, BigTable, Cloud functions, Cloud Workflows, Cloud Composer etc.*** * Strong understanding of data modeling, data warehousing, and data governance principles.* Should be capable of mentoring junior data engineers and assisting them with technical challenges.* Familiarity with orchestration tools like Apache Airflow.* Familiarity with containerization and orchestration (Docker, Kubernetes).* Experience with version control systems (Git) and CI/CD pipelines.* Excellent problem-solving skills and ability to work in a fast-paced environment.* Excellent communication skills.* Hands-on experience with snowflake is a plus.* Experience with big data technologies (Hadoop, Spark, Kafka, etc.) is a plus.* Experience in AWS is a plus.* Should be able to convert business queries into technical documentation.**Education and Experience*** Bachelors degree in Computer Science, Information Systems, Information Technology, or a similar major or?Certified Development?Program* 5+ years of experience building data pipelines using python & GCP (Google Cloud platform).**About Company Statement:****S &P; Global delivers essential intelligence that powers decision making. **We provide the worlds leading organizations with the right data, connected technologies and expertise they need to move ahead. As part of our team, youll help solve complex challenges that equip businesses, governments and individuals with the knowledge to adapt to a changing economic landscape.**S &P; Global Mobility **turns invaluable insights captured from automotive data to help our clients understand todays market, reach more customers, and shape the future of automotive mobility.**About S &P; Global Mobility**At S&P; Global Mobility, we provide invaluable insights derived from unmatched automotive data, enabling our customers to anticipate change and make decisions with conviction. Our expertise helps them to optimize their businesses, reach the right consumers, and shape the future of mobility. We open the door to automotive innovation, revealing the buying patterns of today and helping customers plan for the emerging technologies of tomorrow.For more information, visit .**Whats In It For****You?****Our Purpose:**Progress is not a self-starter. It requires a catalyst to be set in motion. Information, imagination, people, technologythe right combination can unlock possibility and change the world.Our world is in transition and getting more complex by the day. We push past expected observations and seek out new levels of understanding so that we can help companies, governments and individuals make an impact on tomorrow. At S&P; Global we transform data into Essential Intelligence, pinpointing risks and opening possibilities. We Accelerate Progress.**Our People:**We're more than 35,000 strong worldwideso we're able to understand nuances while having a broad perspective. Our team is driven by curiosity and a shared belief that Essential Intelligence can help build a more prosperous future for us all.From finding new ways to measure sustainability to analyzing energy transition across the supply chain to building workflow solutions that make it easy to tap into insight and apply it. We are changing the way people see things and empowering them to make an impact on the world we live in. Were committed to a more equitable future and to helping our customers find new, sustainable ways of doing business. Were constantly seeking new solutions that have progress in mind. Join us and help create the critical insights that truly make a difference.**Our Values:****Integrity, Discovery, Partnership**At S&P; Global, we focus on Powering Global Markets. Throughout our history, the world's leading organizations have relied on us for the Essential Intelligence they need to make confident decisions about the road ahead. We start with a foundation of**integrity** in all we do, bring a spirit of**discovery** to our work, and collaborate in close**partnership** with each other and our customers to achieve shared goals.**Benefits:**We take care of you, so you cantake care of business. We care about our people. Thats why we provide everything youand your careerneed to thrive at S&P; Global.Our benefits include:* Health & WellnessHealth care coverage designed for the mind and body.* Flexible DowntimeGenerous time off helps keep you energized for your time on.* Continuous LearningAccess a wealth of resources to grow your career and learn valuable new skills.* Invest in Your FutureSecure your financial future through competitive pay, retirement planning, a continuing education program with a company-matched student loan contribution, and financial wellness programs.* Family Friendly PerksIts not just about you. S&P; Global has perks for your partners and little ones, too, with some best-in class benefits for families.* Beyond the BasicsFrom retail discounts to referral incentive awardssmall perks can make a big difference.For more information on benefits by country visit**Global Hiring and Opportunity at S &P; Global:**At S&P; Global, we are committed to fostering a connected andengaged workplace where all individuals have access to opportunities based on their skills, experience, and contributions. Our hiring practices emphasize fairness, transparency, and merit, ensuring that we attract and retain top talent. By valuing different perspectives and promoting a culture of respect and collaboration, we drive innovation and power global markets.\-----------------------------------------------------------**Equal Opportunity Employer**S&P; Global is an equal opportunity employer and all qualified candidates will receive consideration for employment without regard to race/ethnicity, color, religion, sex, sexual orientation, gender identity, national origin, age, disability, marital status, military veteran status, unemployment status, or any other status protected by law. Only electronic job submissions will be considered for employment.If you need an accommodation during the application process due to a disability, please send an email to:? ?and your request will be forwarded to the appropriate person.* * **US Candidates Only** The EEO is the Law Poster describes discrimination protections under federal law. Pay Transparency Nondiscrimination Provision - ----------------------------------------------------------- 20 - Professional (EEO-2 Job Categories-United States of America), IFTECH202.1 - Middle Professional Tier I (EEO Job Group), SWP Priority Ratings - (Strategic Workforce Planning)",140525921365,"data warehousing,sql,data modeling,gcp,data governance,continuous integration,kubernetes,ci/cd"
Airflow,AI / Machine Learning / Data Science Engineer,Hissar IT,4-9 Yrs,15-30 Lacs PA,"Pune, Bengaluru",/job-listings-ai-machine-learning-data-science-engineer-hissar-it-pune-bengaluru-4-to-9-years-310525012243,"Required Skills & Qualifications: . 4 to 12 years of experience in Data Science,Machine Learning,or AI. . Proficiency in Python and libraries like Pandas,NumPy,Scikit-learn,TensorFlow,PyTorch .Experience with ML lifecycle tools such as MLflow,Airflow,or SageMaker.Experience working with structured and unstructured data (SQL,NoSQL,text,images,etc.).",310525012243,"Artificial Intelligence,Data Science,ML,Airflow,images,Azure,Hadoop,Scikit-learn"
Airflow,Opportunity | GCP Data Engineer | Tavant India,Tavant Technologies,6-10 Yrs,Not disclosed,"Hybrid - Noida, Hyderabad/Secunderabad, Bangalore/Bengaluru",/job-listings-opportunity-gcp-data-engineer-tavant-india-tavant-technologies-noida-hyderabad-secunderabad-bangalore-bengaluru-6-to-10-years-300425009043,"You will play a key role in ensuring the reliability,performance,and operational excellence of our data platform. . Key Responsibilities: . Design,develop,deploy,and maintain scalable,resilient,and secure data pipelines (batch and streaming) on GCP using services like Cloud Dataflow,Cloud Composer,and Cloud Functions",300425009043,"GCP,Bigquery,Data Flow,Cloud Storage,Airflow,kafka,Cloud,Flow"
Airflow,Sr. Data Engineer,Puresoftware Technology,5-10 Yrs,Not disclosed,Hybrid - Pune,/job-listings-sr-data-engineer-puresoftware-technology-pune-5-to-10-years-200525034897,"**We are looking for a self-starter to join our Data Engineering team. You will work in a****fast-paced environment where you will get an opportunity to build and contribute to the****full lifecycle development and maintenance of the data engineering platform****With the Data Engineering team you will get an opportunity to -****Design and implement data engineering solutions that is scalable, reliable and****secure on the Cloud environment****Understand and translate business needs into data engineering****solutions****Build large scale data pipelines that can handle big data sets using distributed****data processing techniques that supports the efforts of the data science and data****application teams****Partner with cross-functional stakeholder including Product managers, Architects,****Data Quality engineers, Application and Quantitative Science end users to deliver****engineering solutions****Contribute to defining data governance across the platform****Basic Requirements:****A minimum of a BS degree in computer science, software engineering, or related****scientific discipline is desired****3+ years of work experience in building scalable and robust data engineering****solutions****Strong understanding of Object Oriented programming and proficiency with****programming in Python (TDD) and Pyspark to build scalable algorithms****3+ years of experience in distributed computing and big data processing using****the Apache Spark framework including Spark optimization techniques****2+ years of experience with Databricks, Delta tables, unity catalog, Delta****Sharing, Delta live tables(DLT) and incremental data processing****Experience with Delta lake, Unity Catalog****Advanced SQL coding and query optimization experience including the ability to****write analytical and nested queries****3+ years of experience in building scalable ETL/ ELT Data Pipelines on Databricks****and AWS (EMR)****2+ Experience of orchestrating data pipelines using Apache Airflow/ MWAA****Understanding and experience of AWS Services that include ADX, EC2, S3****3+ years of experience with data modeling techniques for structured/****unstructured datasets****Experience with relational/columnar databases - Redshift, RDS and interactive****querying services - Athena/ Redshift Spectrum****Passion towards healthcare and improving patient outcomes****Demonstrate analytical thinking with strong problem solving skills****Stay on top of emerging technologies and posses willingness to learn.****Bonus Experience (optional)****Experience with Agile environment****Experience operating in a CI/CD environment****Experience building HTTP/REST APIs using popular frameworks****Healthcare experience****Kindly acknowledge the email and confirm your presence.Role & responsibilities****Preferred candidate profile**",200525034897,"Airflow,Data Engineering,Data Bricks,Python,SQL,Etl Pipelines,Pyspark,GCP"
Airflow,Data Engineer,Vipany Global Solutions,4-9 Yrs,5-15 Lacs PA,"Mumbai(Mumbai Central), Pune(Pune Nashik Highway), Bengaluru",/job-listings-data-engineer-vipany-global-solutions-mumbai-pune-bengaluru-4-to-9-years-090525007585,"**Role & responsibilities**Job Description:* Experience of 3+ years in data engineering domain* Proficient in SQL.* Good Hands on with python.* Should have knowledge in Dataframe apis using Spark or pandas.* Should be able to design data pipeline solutions* Be able to guide team and help them whenever they are stuck.* Should be able to optimise the SQL queries.* Should have dealt with large volumes of data.Must Have Skills:Strong knowledge of software engineering and development methodologies, Python, SQL,techniques, and tools, including Version Controls (Bitbucket), Issue Tracking(Jira), andSoftware Development Lifecycle (waterfall; agile), unit testing/integration testing, AWSservices, source control usage and practices, Familiar with SQL and relational databasedesign.*Good to have Skills:* Experience with Snowflake and AWS.Key Responsibilities:* 3+ years of Experience* Programming languages: Python and SQL.* Build large volume data pipelines.* Brings an innovation mindset to enhance overall design & performance.* Effectively collaborates with the internal team.* Good analytical skills, quick learner, team player.* Act as a mentor for Junior Developers and offshore teams.* Excellent communication skills and knowledge of Agile methodologyQualifications:* Bachelors or Master Degree in Computer Science with >=3+ years of IT experienceJob Description:5-7 years work expTechnical Skills required: Amazon Connect, AWS Devops, AWS Services, Python, Javascript, IVR,Amazon Lex, Conversational AIAs a SME, design, develop and implement Amazon Connect cloud-based contact center solution Servicesincluding, but not limited to: Call and Queue Flows, Agent Experience, Customer Profile, Tasks, Wisdomand Contact Lens, Step by step guides, Call Recording, Metrics, Contact Lens, CTR Data analysisExperience using Case Management, Customer Profiles, Tasks, Wisdom and Contact Lens, Step by stepguides, Live chat integration to external AI applications. Mandatory Amazon Connect Migration experiencewith minimum of 3 migrations. Configure and maintain end to end contact centre using Amazon Connectand AWS services. Amazon Connect implementation experience of 3 implementations. At least 3 years ofenterprise experience using Amazon Connect contact flows integrated with Python, Lambda and JSON,building applications using AWS services (Cloud Watch, Kinesis, S3, Lex, Poly. Expert of contact centertechnologies, including IVR, cotact flows, routing strategies, and CRM integration. Configure hostintegrations for IVR and agent desktop. Training and upskilling the support team. Create prototype for newfeatures required within Amazon. Excellent communication and interpersonal skills with ability to workindependently and collaboratively in a fast-paced environment. Proven experience in designing andimplementing conversational interfaces using Amazon Lex and have the hands-on experience in buildingChat Applications using Amazon Lex or Druid AI or other technologies. Works in all phases of the softwaredevelopment life cycle including functional analysis, development of technical requirements, technicaldesign, prototyping, coding, testing, deployment, data migration, and support Participate in daily scrums,work with Scrum Master and QA Team on projects, and support delivery timelines and priorities throughstory pointing. Acts as SME along with Finding, analyzing, and fixing bugs and performance problemswhenever and wherever they may occurInterested candidates canContact: 7207997185",090525007585,"Gcp Bigquery,SQL,ETL,AWS,Python,Airflow,Orchestration,Ci Cd Pipeline"
Airflow,GCP - Data Engineer,Miracle Solution,6-10 Yrs,Not disclosed,"Kolkata, Mumbai, New Delhi, Hyderabad, Pune, Chennai, Bengaluru",/job-listings-gcp-data-engineer-miracle-software-solutions-kolkata-mumbai-new-delhi-hyderabad-pune-chennai-bengaluru-6-to-10-years-140525503521,"* Design, develop, and manage scalable data pipelines using Google Cloud services like BigQuery and Dataflow.* Implement data ingestion, transformation, and storage solutions while ensuring high performance and reliability.* Optimize and maintain data workflows using real-time streaming tools, including Apache Beam and Cloud Composer.* Develop ETL and ELT processes to ingest, transform, and store structured and unstructured data from diverse sources in cloud storage.* Ensure data security, governance, and compliance by implementing access control and encryption policies.* Monitor, debug, and optimize data pipelines for seamless analytics and business operations.* Collaborate with data scientists and analysts to deliver reliable, high-quality datasets for decision-making.* Automate data processes using Terraform, Python, or other scripting languages for operational efficiency.* Stay updated with GCP advancements and implement best practices to enhance data engineering workflows.",140525503521,"beam,google cloud services,data pipeline,sql,docker,apache,operations,java"
Airflow,"Senior Data Engineering Analyst - Spark,Scala,Python",Optum,3-8 Yrs,Not disclosed,Noida,/job-listings-senior-data-engineering-analyst-spark-scala-python-optum-global-solutions-india-private-limited-noida-3-to-8-years-270525929675,"Required QualificationsRelevant experience on Databases like Teradata,Snowflake. Hands-on development experience in UNIX scripting.Experience in working on data warehousing projects.Experience with Test Driven Development and Agile methodologies. Sound knowledge of SQL programming and SQL Query Skills.",270525929675,"python,pyspark,sql,spark,sql programming,azure databricks,continuous integration,snowflake"
Airflow,Senior Data Engineering Analyst ADF and SQL,Optum,4-8 Yrs,Not disclosed,Noida,/job-listings-senior-data-engineering-analyst-adf-and-sql-optum-global-solutions-india-private-limited-noida-4-to-8-years-270525929743,"Knowledge on Apache Kafka and Data Streaming. Main tech experience Terraform and AzureSolid problem solving,analytical kills,Good communication and presentation skills,Good attitude and self-motivated.Required QualificationsPreferred QualificationsProven good communication and presentation skills.Proven good attitude and self-motivated .",270525929743,"azure sql dw,sql queries,airflow,data engineering,cloud native,artifactory,continuous integration,kubernetes"
Airflow,"Senior Data Engineering Consultant - SQL Developer, Python",Optum,5-9 Yrs,Not disclosed,Hyderabad,/job-listings-senior-data-engineering-consultant-sql-developer-python-optum-global-solutions-india-private-limited-hyderabad-5-to-9-years-270525929677,"Solid understanding of software engineering principles (micro-services applications and ecosystems) . Fluent in SQL (Snowflake / SQL Server),with experience using Window functions and more advanced features . Understanding of DevOps tools,Git workflow and building CI / CD pipelines .Bachelor s Degreeor higherinDatabase Management,Information Technology,Computer Science or similar .",270525929677,"snowflake,python,airflow,sql server,stored procedures,azure databricks,continuous integration,kubernetes"
Airflow,GCP Data Engineer (Contractual),Smart Source,5-10 Yrs,Not disclosed,"Pune, Bengaluru, Delhi / NCR",/job-listings-gcp-data-engineer-contractual-smart-source-pune-bengaluru-delhi-ncr-5-to-10-years-050525003077,"Shift: UK ShiftRequired Skills: . Strong hands-on experience with GCP services,including Dataproc and BigQueryProficient in PySpark and Java for building distributed data processing pipelinesRelevant Experience: 5+ years in mandatory skillsIAM / VM (Good to have)Experience in developing scalable ETL / ELT pipelines",050525003077,"Bigquery,Data Flow,Dataproc,Google Cloud Platforms,Airflow,Pyspark,Python,gcp migration"
Snowflake,Snowflake Developer - Pan India,Infosys,3-8 Yrs,Not disclosed,"Hyderabad, Chennai, Bengaluru",/job-listings-snowflake-developer-pan-india-infosys-hyderabad-chennai-bengaluru-3-to-8-years-050325025144,Hiring for Snowflake Developer with experience range 2 years & aboveMandatory Skills: SnowflakeEducation: BE/B.Tech/MCA/M.Tech/MSc./MSInterview Mode-F2F,050325025144,"Snowflake,Snowflake Development,snowpro,Pan,Development"
Snowflake,Snowflake Developer,Infosys,5-10 Yrs,Not disclosed,"Hybrid - Hyderabad, Pune, Bengaluru",/job-listings-snowflake-developer-infosys-hyderabad-pune-bengaluru-5-to-10-years-290125020956,"Educational Requirements- Bachelor of Engineering,MCA,BCA,B.tech,B.sc,ms / m.sc . Location- PAN INDIAPreferred Skills: Technology->Data on Cloud-DataStore->SnowflakeGood knowledge on software configuration management systems",290125020956,"Snowflake,Snowflake Developer,Project management,Cloud DataStore,software configuration management,Cloud Storage,Software,Configuration"
Snowflake,Snowflake Developer / Lead,Zensar,5-10 Yrs,17-30 Lacs PA,"Hybrid - Pune, Bengaluru",/job-listings-snowflake-developer-lead-zensar-pune-bengaluru-5-to-10-years-210525019916,"Leadership skills : Strong leadership skills,including experience in leading teams and managing projectsBachelors degree : Bachelors degree in Computer Science,Information Technology,or related fieldRequirements: . 5+ years of experience : Experience in data warehousing,ETL / ELT development,and data modeling",210525019916,"Snowflake,Snowsql,Snowpipe,Development,Leadership"
Snowflake,"Data Engineer (Snowflake, DBT, SAP DS)",Prep Study,3-5 Yrs,Not disclosed,Hyderabad,/job-listings-data-engineer-snowflake-dbt-sap-ds-prep-study-hyderabad-3-to-5-years-300525921827,"Experience with Git,CI / CD,and deployment workflows in a team setting.o Bachelors or masters degree in computer science,Data Engineering,or a related field. . o Certifications such as Snowflake SnowPro,dbt Certified Developer Data Engineering are a plusStrong understanding of ELT patterns and data modelling (Kimball / Dimensional preferred).",300525921827,"Snowflake,Data Modelling,Python basic,RBAC,SAP DS,DBT,Azure Data Lake,SQL"
Snowflake,Snowflake data engineer,Jade Global,3-7 Yrs,Not disclosed,Pune,/job-listings-snowflake-data-engineer-jade-global-software-pvt-ltd-pune-3-to-7-years-230525922678,"In addition to that,they should bring experience in at least one other programming language,with a proficiency in Python being a key requirementThe ideal candidate should also have.",230525922678,"aws iam,devops,snowflake,python,sql server,hive,data warehousing,data architecture"
Snowflake,Snowflake Data Engineer-DBT,Mississippi Consultants Pune,5-8 Yrs,12-16 Lacs PA,"Hyderabad, Pune, Bengaluru",/job-listings-snowflake-data-engineer-dbt-mississippi-consultants-pune-hyderabad-pune-bengaluru-5-to-8-years-310525019297,"Experience designing highly scalable ETL / ELT processes with complex data transformations,data formats including error handling and monitoringSnowflake certified is preferableShould be willing to work in implementation & support projectsCollaborate with other team members to ensure the proper delivery of the requirementGood working knowledge of ETL / ELT tool",310525019297,"Snowsql,Snowflake,DBT,SQL,Data"
Snowflake,Snowflake Data Engineer,Stratacent,3-8 Yrs,Not disclosed,Gurugram,/job-listings-snowflake-data-engineer-stratacent-india-private-limited-gurugram-3-to-8-years-300525503625,"**Title/Position:** Snowflake Data Engineer**Job Location:** Gurugram**Experience:** 3+ Years**Employment Type:** Full Time**Shift Time:** 10:00 AM-7:00 PM/11:00 AM-8:00 PM IST* Proven years experience working in client-facing.* Proven years experience in data warehouse, ETL tool (such as Informatica or any ETL tool experience).* Proven years hands-on experience with any data warehouse whether on-prem or cloud based such as Oracle, Teradata, DB2, Snowflake etc.* SQL Proficiency High/ Expert is a Must,* Excellent understanding of Data warehousing concepts, data warehousing design and implementation.* Proven years of experience with Snowflake or Snowflake certified professional.* Strong analytical and problem-solving skills with a keen attention to detail.* Should be able to deliver tasks independently with least supervision.* Should be able to guide / help junior team members.* Should have attitude to learn new skills / technologies being used in client environments.**Company Profile:-**Stratacent is an IT Consulting and Services firm, headquartered in Jersey City, NJ, with two global delivery centers in New York City area and New Delhi area plus offices in London, Canada and Pune, India.We are a leading IT services provider focusing in Financial Services, Insurance, Healthcare and Life Sciences. We help our customers in their digital transformation journey and provides services/ solutions around Cloud Infrastructure, Data and Analytics, Automation, Application Development and ITSM.We have partnerships with SAS, Automation Anywhere, Snowflake, Azure, AWS and GCP.URL - http://stratacent.com**Employee Benefits:**Group Medical InsuranceCab facilityMeals/snacksContinuous Learning ProgramStratacentIndia Private Limited is an equal opportunity employer and will not discriminate against any employee or applicant for employment on the basis of race, color, creed, religion, age, sex, national origin, ancestry, handicap, or any other factors.."",",300525503625,"Automation,SAS,Db2,Application development,HTTP,Informatica,Oracle,Teradata"
Snowflake,Data Engineer - Snowflake & Python,Useready,3-5 Yrs,Not disclosed,"Mohali, Pune",/job-listings-data-engineer-snowflake-python-useready-technology-mohali-pune-3-to-5-years-220525502313,"**Job Title: Data Engineer - Snowflake & Python ****About the Role:**We are seeking a skilled and proactive **Data Developer** with 3-5 years of hands-on experience in **Snowflake** , **Python** , **Streamlit** , and **SQL** , along with expertise in consuming **REST APIs** and working with modern **ETL tools** like **** Matillion, Fivetran etc. The ideal candidate will have a strong foundation in **data modeling** , **data warehousing** , and **data profiling** , and will play a key role in designing and implementing robust data solutions that drive business insights and innovation.**Key Responsibilities:*** Design, develop, and maintain data pipelines and workflows using Snowflake and an ETL tool (e.g., Matillion, dbt, Fivetran, or similar).* Develop data applications and dashboards using Python and Streamlit.* Create and optimize complex SQL queries for data extraction, transformation, and loading.* Integrate REST APIs for data access and process automation.* Perform data profiling, quality checks, and troubleshooting to ensure data accuracy and integrity.* Design and implement scalable and efficient data models aligned with business requirements.* Collaborate with data analysts, data scientists, and business stakeholders to understand data needs and deliver actionable solutions.* Implement best practices in data governance, security, and compliance.**Required Skills and Qualifications:*** 3-5 years of professional experience in a data engineering or development role.* Strong expertise in **Snowflake** , including performance tuning and warehouse optimization.* Proficient in **Python** , including data manipulation with libraries like Pandas.* Experience building web-based data tools using **Streamlit** .* Solid understanding and experience with **RESTful APIs** and JSON data structures.* Strong SQL skills and experience with advanced data transformation logic.* Experience with an ETL tool commonly used with Snowflake (e.g., **dbt** , **Matillion** , **Fivetran** , **Airflow** ).* Hands-on experience in **data modeling** (dimensional and normalized), **data warehousing concepts** , and **data profiling techniques** .* Familiarity with version control (e.g., Git) and CI/CD processes is a plus.**Preferred Qualifications:*** Experience working in cloud environments (AWS, Azure, or GCP).* Knowledge of data governance and cataloging tools.* Experience with agile methodologies and working in cross-functional teams.",220525502313,"Performance tuning,Version control,Data modeling,Agile,Data structures,JSON,Agile methodology,Troubleshooting"
Snowflake,"Senior Data Engineer (Snowflake & DBT, SAP DS)",SMART4TALENT,6-10 Yrs,Not disclosed,Hyderabad,/job-listings-senior-data-engineer-snowflake-dbt-sap-ds-smart4talent-hyderabad-6-to-10-years-300525921824,"Bachelors or masters degree in computer science,Data Engineering,or a related fieldCertifications such as Snowflake SnowPro Advanced,dbt Certified Developer are a plusExperience implementing Medallion Architecture (Bronze / Silver/Gold layers)Exposure to AI / ML data pipelines,feature stores,or MLflow for model tracking (good to have)",300525921824,"Snowflake,Data Modelling,Python basic,RBAC,SAP DS,DBT,Azure Data Lake,SQL"
Snowflake,Senior Data Engineer & Lead - Snowflake & ETL,Reflections Global,6-11 Yrs,Not disclosed,"Kochi, Bengaluru, Thiruvananthapuram",/job-listings-senior-data-engineer-lead-snowflake-etl-reflections-global-kochi-bengaluru-thiruvananthapuram-6-to-11-years-290525502742,"Expertise in Dimension Modeling is a must . Strong problem-solving and analytical skills,with the ability to derive actionable insights from dataWe contact our candidates only through our official website or LinkedIn and all employment related mails are sent through the official HR email idExperience in data visualization and reporting tools (e.g",290525502742,"data cleansing,Performance tuning,Data validation,Manager Quality Assurance,Data modeling,Schema,data visualization,Reporting tools"
Snowflake,Snowflake Data Engineer,Hexaware Technologies,7-12 Yrs,Not disclosed,"Hybrid - Hyderabad, Bengaluru",/job-listings-snowflake-data-engineer-hexaware-technologies-hyderabad-bengaluru-7-to-12-years-310525017977,"Preferred Location .Experience: 7-10 yrs . Notice period : Imm - 30 days .Primary Skills: Snowflake (4+ years of experience),Python,PySpark,SQL Stored ProceduresTotal Experience",310525017977,"Pyspark,Stored Procedures,Snowflake,SQL,Python,AWS,Data,Procedures"
Snowflake,"Senior Data Engineer (Snowflake, DBT)",Allegis Global Solutions (AGS),5-10 Yrs,Not disclosed,Remote,/job-listings-senior-data-engineer-snowflake-dbt-allegis-global-solutions-ags-bengaluru-5-to-10-years-191224000083,"Job Details . Technical Expertise: . Strong proficiency in Snowflake architecture,including data sharing,partitioning,clustering,and materialized viewsPreferred Qualifications: . Certifications in Snowflake,DBT,or Azure Data EngineeringAdvanced experience with DBT for data transformations and workflow management",191224000083,"Snowflake,Data Build Tool,Azure,Build,Senior,Build Automation,Tools,Microsoft Azure"
Snowflake,Snowflake Developer,SP Staffing,3-8 Yrs,Not disclosed,"Hybrid - Hyderabad, Pune, Bengaluru",/job-listings-snowflake-developer-sp-staffing-hyderabad-pune-bengaluru-3-to-8-years-260525018368,"Experience Required :3 to 10 yrs . Work Location : Bangalore / Hyderabad/Bhubaneswar / Pune/Gurgaon / Noida/KochiRequired Skills,. Snowflake",260525018368,"snowflake developer,python,Snowflake Sql,Snowsql,Snowflake Procedures,Snowflake,Snowflake Development,Snow Flake Schema"
Snowflake,Snowflake data engineer,Jade Global,3-7 Yrs,Not disclosed,Pune,/job-listings-snowflake-data-engineer-jade-global-software-pvt-ltd-pune-3-to-7-years-230525922674,"Snowflake data engineer1Overall Experience 5+ years of experience in IICS and SnowflakeProven experience in implementing ETL solutions with a focus on IICS and Snowflake.Strong hands-on development experience in IICS, including CDI, CAI, and Mass Ingestion.Proficiency in using various connectors for different source/file formats and databases.Knowledge of web services and their integration into ETL processes.Administration skills related to IICS, ensuring a smooth operational environment.Proven experience as a Snowflake Developer with a strong focus on data warehousing.Hands-on experience in designing and implementing data models within the Snowflake environment.Proficient in developing ETL processes using Snowflake features and SQL.Knowledge of security best practices and access control within Snowflake.Familiarity with data integration and data warehouse concepts.Experience with data migration to Snowflake from other platforms is a plus.Excellent problem-solving skills with the ability to analyze and resolve critical issues.Strong organizational and project management skills.Effective communication skills for customer interactions and status updates.Ability to thrive in a fast-paced, dynamic, client-facing role where delivering solid work products to exceed high expectations is a measure of success.Eager to contribute to a team-oriented environment.Strong prioritization and multi-tasking skills with a track record of meeting deadlines.Ability to be creative and analytical in a problem-solving environment.Effective verbal and written communication skills.Adaptable to new environments, people, technologies, and processesAbility to manage ambiguity and solve undefined problems.",230525922674,"data warehousing,dbms,iics,project management,etl process,web services,jsp,data migration"
Snowflake,Snowflake data engineer,Jade Global,5-10 Yrs,Not disclosed,Pune,/job-listings-snowflake-data-engineer-jade-global-software-pvt-ltd-pune-5-to-10-years-170525500652,"Proven experience in implementing ETL solutions with a focus on IICS and Snowflake. Strong hands-on development experience in IICS,including CDI,CAI,and Mass Ingestion. Proficiency in using various connectors for different source / file formats and databases.Overall Experience : 5+ years of experience in IICS and Snowflake .",170525500652,"Access control,Data migration,Web services,Analytical,Project management,Focus,Management,Operations"
Snowflake,Data Engineer Snowflake + Kafka,Zensar,5-6 Yrs,Not disclosed,Pune,/job-listings-data-engineer-snowflake-kafka-zensar-technologies-pune-5-to-6-years-170525500226,"**Key**\- Build, optimize, and maintain efficient data management workflows for event-driven processes.\- Write highly efficient PL/SQL blocks to process and manipulate data.\- Work on Snowflake pipelines (e.g., Snowpipe) for real-time and batch data ingestion.\- Collaborate with cross-functional teams to design and deliver scalable solutions.\- Support and monitor the live and staging environments, especially during critical events.\- Develop and maintain shell scripts for automation and orchestration of database tasks.\- Work with Kafka or Pub/Sub for real-time event streaming (optional but preferred).\- Ensure the high quality of deliverables by participating in code reviews and adhering to best practices for database development.**Qualification**\- 5-6 years of professional experience as a Data Engineer or in a similar role.\- Strong expertise in writing PL/SQL blocks for Oracle or other relational databases.\- Hands-on experience with Snowflake and its ecosystem (e.g., Snowpipe, data sharing, and performance optimization).\- Proficiency in Oracle database management and SQL performance tuning.\- Experience with shell scripting for automation tasks.",170525500226,"Oracle database,Performance tuning,Automation,orchestration,Data management,Database management,Shell scripting,PLSQL"
Snowflake,"Sr Data Engineering Lead-SQL,Big data,Generative AI,Snowflake,Kafka",Optum,6-10 Yrs,Not disclosed,Gurugram,/job-listings-sr-data-engineering-lead-sql-big-data-generative-ai-snowflake-kafka-optum-global-solutions-india-private-limited-gurugram-6-to-10-years-270525929770,"* Lead technology solution design and delivery* Create and maintain optimal data solutions architecture and AI models* Works with business partners to document complex company-wide acceptance test plans.* Work concurrently on several projects, each with specific instructions that may differ from* Assemble large, complex data sets that meet functional / non-functional business requirements.* Identify, design, and implement internal process improvementsautomating manual processes, optimizing data delivery, re-designing infrastructure for greater scalability, etc.* Build the infrastructure required for optimal extraction, transformation, and loading of data from a wide variety of data sources using SQL and cloud 'big data' technologies.* Build analytics tools that utilize the data pipeline to provide actionable insights into customer acquisition, operational efficiency and other key business performance metrics.* Work with stakeholders including the Executive, Product, Data and Design teams to assist with business-critical data insights, technical issues and support their data infrastructure needs.* Keep our data separated and secure across national boundaries through multiple data centers and cloud regions.* Create data tools for analytics and data scientist team members that assist them in building and optimizing our product into an innovative industry leader.* Work with data and analytics experts to strive for greater functionality in our data systems.* Build processes supporting data transformation, data structures, metadata, dependency and workload management.* Troubleshoot production support issues post release deployment and come up with solutions* Explain, Socialize and Vet designs internal and external stakeholders* Undergraduate degree or equivalent experience.* Undergraduate Degree in Engineering or equivalent* Over 7 years of experience in Data Engineering and Advanced Analytics* Strong experience in build Generative AI based solutions for data management (data pipelines, data standardization, data quality) and data analytics.* Advanced working SQL knowledge and experience working with relational databases, query authoring (SQL) as well as working familiarity with a variety of databases.* Experience building and optimizing 'big data' data pipelines, architectures and data sets.* Experience in Cloud technologies and SNOWFLAKE* Experience in Kafka development* Experience in Python/Java programing* Experience in creating business data models* Experience in Report development and dashboarding* Strong Experience in driving Customer Experience* Experience in working with agile teams* Experience in Healthcare Clinical Domains* Experience performing root cause analysis on internal and external data and processes to answer specific business questions and identify opportunities for improvement.* Strong analytic skills related to working with unstructured datasets.* A successful history of manipulating, processing and extracting value from large, disconnected datasets.* Working knowledge of message queuing, stream processing, and highly scalable 'big data' data stores.* Strong project management and organizational skills.* Experience supporting and working with cross-functional teams in a dynamic environment.* * **Careers with Optum.** Here's the idea. We built an entire organization around one giant objective; make the health system work better for everyone. So when it comes to how we use the world's large accumulation of health-related information, or guide health and lifestyle choices or manage pharmacy benefits for millions, our first goal is to leap beyond the status quo and uncover new ways to serve. Optum, part of the UnitedHealth Group family of businesses, brings together some of the greatest minds and most advanced ideas on where health care has to go in order to reach its fullest potential. For you, that means working on high performance teams against sophisticated challenges that matter. Optum, incredible ideas in one incredible company and a singular opportunity to do **your life's best work.SM* *** ****Diversity creates a healthier atmosphereUnitedHealth Group is an Equal Employment Opportunity/Affirmative Action employer and all qualified applicants will receive consideration for employment without regard to race, color, religion, sex, age, national origin, protected veteran status, disability status, sexual orientation, gender identity or expression, marital status, genetic information, or any other characteristic protected by law.* * UnitedHealth Group is a drug-free workplace. Candidates are required to pass a drug test before beginning employment.",270525929770,"advanced analytics,project management,python,data management,data engineering,hive,snowflake,data analytics"
Snowflake,Snowflake Developer,MSys Technologies,5-10 Yrs,Not disclosed,"Hybrid - Pune, Bengaluru",/job-listings-snowflake-developer-msys-technologies-pune-bengaluru-5-to-10-years-280525018564,"**Key Responsibilities:*** Design, develop, and maintain data pipelines and integrations using Snowflake.* Write efficient and complex SQL queries for data transformation and reporting.* Develop automation scripts and tools using Python.* Optimize data workflows for performance and scalability.* Collaborate with data engineers, analysts, and business stakeholders to understand data needs.* Ensure data accuracy, consistency, and security across various data layers.",280525018564,"snowflake,DBT Matillion,AWS,Python,Development"
Snowflake,Lead Data Engineer ( Snowflake + ADF + SQL),Shashwath Solution,10-12 Yrs,Not disclosed,"Indore, Hyderabad, Pune",/job-listings-lead-data-engineer-snowflake-adf-sql-shashwath-solution-indore-hyderabad-pune-10-to-12-years-280525917910,"Required Technical Skills: T-SQL,SQL Server,MSBI (SQL Server Integration Services,Reporting Services),Snowflake,Azure Data Factory (ADF),SSIS,Azure Data Lake StorageProficient in designing and developing data pipelines,data integration,and data management workflowsNice to Have: Experience with Power BI for data visualization and reporting",280525917910,"Data Engineering,T-SQL,Business Intelligence,ADF,Power BI,Data Management,Azure Databricks,SQL Server"
Snowflake,Snowflake Data Engineer,Apptad,6-11 Yrs,Not disclosed,Remote,/job-listings-snowflake-data-engineer-apptad-bengaluru-6-to-11-years-290525017435,"Required Qualifications: . Bachelors degree in Computer Science,Information Systems,or a related fieldImmediate Joiners preferred .Experience - 6-12 years.35 years of experience in data engineering,cloud architecture,or Snowflake administrationHands-on experience with Snowflake features: Snowpipe,Streams,Tasks,External Tables,and Secure Data Sharing",290525017435,"ingress,snowflake engineer,data engineer,Snowflake,orchestration tools,Cloud,engress,SQL"
Snowflake,Snowflake Developer- Pune (Pan India Infosys),Infosys,2-7 Yrs,Not disclosed,"Hybrid - Hyderabad, Chennai, Bengaluru",/job-listings-snowflake-developer-pune-pan-india-infosys-infosys-hyderabad-chennai-bengaluru-2-to-7-years-210325023026,"Exciting Snowflake developer Job Opportunity at Infosys!We are looking for skilled Snowflake Developers to join our dynamic team **PAN INDIA.** If you have a passion for technology and a minimum of 2 to 9 years of hands-on experience in snowflake application development, this is your chance to make an impact.At Infosys, we value innovation, collaboration, and diversity. We believe that a diverse workforce drives creativity and fosters a richer company culture. Therefore, we strongly encourage applications from all genders and backgrounds.Ready to take your career to the next level? Join us in shaping the future of technology. Visit our careers page for more details on how to apply.",210325023026,"Snowflake,Snowflake Sql,Snowflake Db,Db,Pan,SQL,Development"
Snowflake,Snowflake Developer - Infosys @ PAN INDIA,Infosys,2-7 Yrs,Not disclosed,"Hyderabad, Chennai, Bengaluru",/job-listings-snowflake-developer-infosys-pan-india-infosys-hyderabad-chennai-bengaluru-2-to-7-years-090525025128,Hiring for Snowflake Developer with experience range 2 years & aboveMandatory Skills: Snowflake DeveloperEducation: BE/B.Tech/MCA/M.Tech/MSc./MSInterview Mode-F2,090525025128,"Snowflake,snowflake developer,Snow Development,Snow,Pan,Development"
Snowflake,Snowflake Developer,HCLTech,5-10 Yrs,9-19 Lacs PA,Chennai,/job-listings-snowflake-developer-hcltech-chennai-5-to-10-years-260525010452,"**Roles and Responsibilities*** Design, develop, test, deploy, and maintain large-scale data warehousing solutions using Snowflake SQL.* Collaborate with cross-functional teams to gather requirements and deliver high-quality solutions on time.* Develop complex queries to optimize database performance and troubleshoot issues.* Implement star schema designs for efficient data modeling and querying.* Participate in code reviews to ensure adherence to coding standards.",260525010452,"Snowflake,Star Schema,Snowflake Sql,Snowsql,Snowflake Db,Snowpipe,Development,Schema"
Snowflake,Snowflake Developer,Infosys,3-5 Yrs,Not disclosed,Bengaluru,/job-listings-snowflake-developer-infosys-limited-bengaluru-3-to-5-years-200525923264,"MCA,MSc,MTech,Bachelor of Engineering,BCA,BSc,BTech . Service LinePreferred .Good understanding of SDLC and agile methodologies",200525923264,"snowflake,sql,etl,sdlc,agile methodology,hive,python,oracle"
Snowflake,"Senior Engineer, Python Data Engineer (Snowflake SQL)",Nagarro,3-5 Yrs,Not disclosed,"Pune, Gurugram",/job-listings-senior-engineer-python-data-engineer-snowflake-sql-nagarro-pune-gurugram-3-to-5-years-300425018591,"Cloud platform experience (AWS,Azure,GCP) and integration techniquesREQUIREMENTS: . Total experience 3+yearsExperience with pharmaceutical data (e.g.,clinical trials,sales,patient data,regulatory,RWE) is preferredHands on experience as a Snowflake SQL DeveloperExperience working with structured and semi-structured data (JSON,Parquet,Avro) in Snowflake",300425018591,"Python Data,Snowflake,SQL,Data,Snowflake SQL,Python,Senior"
Snowflake,Snowflake Developer,Wipro,5-8 Yrs,Not disclosed,Bengaluru,/job-listings-snowflake-developer-wipro-limited-bengaluru-5-to-8-years-230525924766,"******Role Purpose**The purpose of the role is to support process delivery by ensuring daily performance of the Production Specialists, resolve technical escalations and develop technical capability within the Production Specialists.**********Do*****Oversee and support process by reviewing daily transactions on performance parameters*** Review performance dashboard and the scores for the team* Support the team in improving performance parameters by providing technical support and process guidance* Record, track, and document all queries received, problem-solving steps taken and total successful and unsuccessful resolutions* Ensure standard processes and procedures are followed to resolve all client queries* Resolve client queries as per the SLA’s defined in the contract* Develop understanding of process/ product for the team members to facilitate better client interaction and troubleshooting* Document and analyze call logs to spot most occurring trends to prevent future problems* Identify red flags and escalate serious client issues to Team leader in cases of untimely resolution* Ensure all product information and disclosures are given to clients before and after the call/email requests* Avoids legal challenges by monitoring compliance with service agreements*******Handle technical escalations through effective diagnosis and troubleshooting of client queries*** Manage and resolve technical roadblocks/ escalations as per SLA and quality requirements* If unable to resolve the issues, timely escalate the issues to TA & SES* Provide product support and resolution to clients by performing a question diagnosis while guiding users through step-by-step solutions* Troubleshoot all client queries in a user-friendly, courteous and professional manner* Offer alternative solutions to clients (where appropriate) with the objective of retaining customers’ and clients’ business* Organize ideas and effectively communicate oral messages appropriate to listeners and situations* Follow up and make scheduled call backs to customers to record feedback and ensure compliance to contract SLA’s*******Build people capability to ensure operational excellence and maintain superior customer service levels of the existing account/client*** Mentor and guide Production Specialists on improving technical knowledge* Collate trainings to be conducted as triage to bridge the skill gaps identified through interviews with the Production Specialist* Develop and conduct trainings (Triages) within products for production specialist as per target* Inform client about the triages being conducted* Undertake product trainings to stay current with product features, changes and updates* Enroll in product specific and any other trainings per client requirements/recommendations* Identify and document most common problems and recommend appropriate resolutions to the team* Update job knowledge by participating in self learning opportunities and maintaining personal networks******Deliver**NoPerformance ParameterMeasure1ProcessNo. of cases resolved per day, compliance to process and quality standards, meeting process level SLAs, Pulse score, Customer feedback, NSAT/ ESAT2Team ManagementProductivity, efficiency, absenteeism3Capability developmentTriages completed, Technical Test performanceMandatory**Skills:*** Snowflake.Experience5-8 Years.",230525924766,"snowflake,data warehousing,sql,etl,informatica,hive,python,oracle"
Snowflake,Snowflake Data Engineer,Safran Engineering Services,4-7 Yrs,Not disclosed,"Mumbai, Navi Mumbai, Mumbai (All Areas)",/job-listings-snowflake-data-engineer-safran-engineering-services-mumbai-navi-mumbai-mumbai-all-areas-4-to-7-years-240525014137,"We are looking for an experienced Data Engineer to design, develop, and maintain our data pipelines, primarily focused on ingesting data into our Snowflake data platform. The ideal candidate will have strong expertise in Snowflake and practical experience with AWS services, particularly using S3 as a landing zone and an entry point to the Snowflake environment. You will be responsible for building efficient, reliable, and scalable data pipelines that are critical for our data-driven decision-making processes.**Role & responsibilities**1\. Design, develop, implement, and maintain scalable and robust data pipelines to ingest data from various sources into the Snowflake data platform.2\. Utilize AWS S3 as a primary landing zone for data, ensuring efficient data transfer and integration with Snowflake.3\. Develop and manage ETL/ELT processes, focusing on data transformation, cleansing, and loading within the Snowflake and AWS ecosystem.4.Write complex SQL queries and stored procedures in Snowflake for data manipulation, transformation, and performance optimization.5\. Monitor, troubleshoot, and optimize data pipelines for performance, reliability, and scalability.6\. Collaborate with data architects, data analysts, data scientists, and business stakeholders to understand data requirements and deliver effective solutions.7\. Ensure data quality, integrity, and governance across all data pipelines and within the Snowflake platform.8\. Implement data security best practices in AWS and Snowflake.9\. Develop and maintain comprehensive documentation for data pipelines, processes, and architectures.10\. Stay up-to-date with emerging technologies and best practices in data engineering, particularly related to Snowflake and AWS.11\. Participate in Agile/Scrum development processes, including sprint planning, daily stand-ups, and retrospectives.**Preferred candidate profile**1\. Strong, hands-on proficiency with Snowflake: In-depth knowledge of Snowflake architecture, features (e.g., Snowpipe, Tasks, Streams, Time Travel, Zero-Copy Cloning).Experience in designing and implementing Snowflake data models (schemas, tables, views).Expertise in writing and optimizing complex SQL queries in Snowflake.Experience with data loading and unloading techniques in Snowflake.2\. Solid experience with AWS Cloud services:Proficiency in using AWS S3 for data storage, staging, and as a landing zone for Snowflake.Experience with other relevant AWS services (e.g., IAM for security, Lambda for serverless processing, Glue for ETL - if applicable).3\. Strong experience in designing and building ETL/ELT data pipelines. Proficiency in at least one programming language commonly used in data engineering (e.g., Python, Scala, Java). Python is highly preferred.",240525014137,"Snowflake,Data Engineer,ETL,AWS,Data Engineering,Data"
Snowflake,"Data Engineer - Databricks, Snowflake, Fabric",Usxi Group,5-9 Yrs,Not disclosed,Remote,/job-listings-data-engineer-databricks-snowflake-fabric-usxi-group-chennai-5-to-9-years-260525005684,"Additionally,you must be capable of developing databases using SSIS packages,T-SQL,MSSQL,and MySQL scripts.Experienced working with agile project management methodologies. Computer Science Degree / Diploma. Microsoft Certified: DP203 - Azure Data Engineer AssociateThe candidate must also be technologically adept,demonstrating strong computer skills",260525005684,"Snowflake,Data Bricks,Python,SQL,Airflow,Pyspark,ETL,Fabric"
Snowflake,Data Engineer- Snowflake,Pure Storage,6-11 Yrs,Not disclosed,Bengaluru,/job-listings-data-engineer-snowflake-pure-storage-bengaluru-6-to-11-years-240525500991,Experience with Cloud Database systems like Snowflake or AWS Redshift will be a plusThis is a full time position and the candidate is expected to report into Pure Storage s Bangalore Office. WHAT YOU CAN EXPECT FROM US: .3+ years experience in Snowflake with knowledge in distributed computing preferred,240525500991,"Computer science,Manager Quality Assurance,Data modeling,Database design,Schema,Analytics,SQL,Python"
Snowflake,Snowflake Developer,Black And White Business Solutions,4-9 Yrs,Not disclosed,"Hyderabad, Pune, Gurugram",/job-listings-snowflake-developer-black-and-white-business-solutions-hyderabad-pune-gurugram-4-to-9-years-200525015717,Job Title : Snowflake Developer. Qualification : Any Graduate or Above. .,200525015717,"Snowflake,Microsoft Azure,AWS,Python,Snowflake Sql,Snowsql,Ci/Cd,Snowpipe"
Snowflake,Senior Data Engineer ( Snowflake ),Agivant Technologies,5-8 Yrs,Not disclosed,"Mumbai, Delhi / NCR, Bengaluru",/job-listings-senior-data-engineer-snowflake-agivant-technologies-mumbai-delhi-ncr-bengaluru-5-to-8-years-190525910812,"Mandatory: . Bachelors degree in Computer Science,Engineering,or a related fieldMinimum 3+ years of professional level experience with Python languages for data manipulation and automation5+ years of experience as a Data Engineer with a strong focus on ELT / ETL processesWorking experience with Elastic Search and its application in data pipelines",190525910812,"Snowflake,Data Engineering,data modelling,AWS S3,ETL,Elastic Search,Python,SQL"
Snowflake,Snowflake Developer,BOYEN HADDIN CONSULTING AND TECHNOLOGY PRIVATE LIM ITED,5-10 Yrs,Not disclosed,Bengaluru,/job-listings-snowflake-developer-boyen-haddin-consulting-and-technology-private-lim-ited-bengaluru-5-to-10-years-290525930184,"Hands on experience with Snowflake and Python a must.Hands on experience with Apache Spark a must.Hands on experience with DBT preferred.Experience with performance tuning SQL queries, Spark job, and stored procedures.An understanding of E-R data models (conceptual, logical, and physical).",290525930184,"Snowflake,DBT,Spark,Python,SQL,Apache Spark,Development,Apache"
Snowflake,Lead Snowflake Developer / Senior SnowFlake Developer,Concept Consultant Service,8-13 Yrs,30-45 Lacs PA,Hybrid - Bengaluru,/job-listings-lead-snowflake-developer-senior-snowflake-developer-concept-consultant-service-bengaluru-8-to-13-years-290525020998,"**Role & responsibilities****1\. Senior Snowflake Developer-Experience- 8+ Years****Location- Bangalore- Mahadevapaura( Hybrid- UK shift)- 3 days office****Notice Period- immediate to 15 days****CTC: 37 Lakhs****JD:****Summary****ThoughtFocus is looking for a senior snowflake developer for our NYC and London based financial services client operating in Public/Private Loans, CLOs, and Long/Short Credit.****You will play a pivotal role in accomplishing the successful delivery of our strategic initiatives. You will be responsible for developing solutions using technologies like Snowflake, Coalesce & Fivetran.****Location: Bengaluru, India****Requirements:*** **IT experience of 8+ years with a minimum of 3+ years of experience as a Snowflake Developer.*** **Design, develop, and optimize Snowflake objects such as databases, schemas, tables, views, and store procedures.*** **Expertise in Snowflake utilities such as Snow SQL, Snow Pipe, Stages, Tables, Zero Copy Clone, Streams and Tasks, Time travel, data sharing, data governance, and row access policy.*** **Experience in migrating data from Azure Cloud to Snowflake, ensuring data integrity, performance optimization, and minimal disruption to business operations.*** **Experience in Snow pipe for continuous loading and unloading data into Snowflake tables.*** **Experience in using the COPY, PUT, LIST, GET, and REMOVE commands.*** **Experience in Azure integration and data loading (Batch and Bulk loading).*** **Experience in creating the System Roles & Custom Roles and Role Hierarchy in Snowflake.*** **Expertise in masking policy and network policy in Snowflake.*** **Responsible for designing and maintaining ETL tools (Coalesce & Fivetran) that include extracting the data from the MS-SQL Server database and transforming the data as per Business requirements.*** **Extensive experience in writing complex SQL Queries, Stored Procedures, Views, Functions, Triggers, Indexes, and Exception Handling using MS-SQL Server (TSQL).*** **Effective communication skills and interpersonal skills.*** **Ability to influence and collaborate effectively with cross-functional teams.*** **Exceptional problem-solving abilities.*** **Experience in working in an agile development environment.*** **Experience working in a fast-paced, dynamic environment.*** **Good to have some prior experience or high-level understanding of hedge funds, private debt, and private equity.****What's on offer*** **Competitive and above market salary.*** **Hybrid work schedule.*** **Opportunity to get exposure and technology experience in global financial markets.****Education*** **Bachelor's degree in Computer Science / IT / Finance / Economics or equivalent.****2\. Please find the below Lead Snowflake JD****Location: Bangalore( UK Shift) 3 days work from Office****CTC:45 Lakhs****13+ years of IT experience, a proven track record of successfully leading a development team to deliver SQL and Snowflake complex projects.****• Strong communication skills and interpersonal skills.****• Ability to influence and collaborate effectively with cross-functional teams.****• Exceptional problem-solving and decision-making abilities.****• Experience in working in an agile development environment.****• Experience working in a fast-paced, dynamic environment.****• Good to have some prior experience or high-level understanding of hedge funds, private debt, and private equity.*** **SQL, Snowflake development via expertise in all aspects related to analysis, understanding the business requirement, taking an optimized approach to developing code, and ensuring data quality in outputs presented*** **Advanced SQL to create and optimize stored procedures, functions, and performance optimize*** **Approach analytically to translate data into last mile SQL objects for consumption in reports and dashboards*** **5+ years of experience in MS SQL, Snowflake*** **3+ years of experience in teams where SQL outputs were consumed via Power BI / Tableau / SSRS and similar tools*** **Should be able to define and enforce Best Practices*** **Good communication skills to be able to discuss and deliver requirements effectively with the client****Preferred candidate profile**",290525020998,"MS SQL,Snowflake Sql,Snowflake Development,Azure Migration,SQL,ETL Tool,Tools,Microsoft Azure"
Snowflake,Snowflake Data Engineer,Epam Systems,5-10 Yrs,Not disclosed,Hybrid - Chennai,/job-listings-snowflake-data-engineer-epam-systems-chennai-5-to-10-years-210525032179,"Strong programming experience with PythonExperience with workflow management tools like Argo / Oozie/AirflowExperience in Snowflake modelling - roles,schema,databasesExperience in data Modeling (Data Vault)Experience in design and development of data transformation pipelines using the DBT framework",210525032179,"Snowflake,Python,Azure Cloud,AWS,SQL,Microsoft Azure,Data,Cloud"
Snowflake,Snowflake Developer,Black And White Business Solutions,4-9 Yrs,Not disclosed,"Pune, Bangalore Rural, Gurugram",/job-listings-snowflake-developer-black-and-white-business-solutions-pune-bangalore-rural-gurugram-4-to-9-years-210525015041,Job Title : Snowflake Developer. Qualification : Any Graduate or Above. .,210525015041,"Snowflake,Snowsql,Kafka,Snowflake Modeling,Snowpipe,SQL,Data Quality,Snowflake Sql"
Snowflake,Snowflake Developer,Black And White Business Solutions,4-9 Yrs,Not disclosed,"Hyderabad, Pune, Bengaluru",/job-listings-snowflake-developer-black-and-white-business-solutions-hyderabad-pune-bengaluru-4-to-9-years-170525019593,"Qualification: Bachelors or Masters degree in Computer Science,Information Technology,or a related fieldLocation: . Bangalore (BLR). Hyderabad (HYD). Pune. Bhubaneswar (BBSR). Noida. Notice Period: Immediate up to 30 days preferredExperience with Informatica,Matillion,or similar tools.",170525019593,"Snowpipe,SQL,Snowflake,dbt,Python,Snowsql,Snowflake Modeling,Snowflake Sql"
Snowflake,Snowflake Data Engineer,Teamware Solutions ( A division of Quantum Leap Co     nsulting Private LTD).,4-5 Yrs,Not disclosed,Karnataka,/job-listings-snowflake-data-engineer-teamware-solutions-a-division-of-quantum-leap-co-nsulting-private-ltd-karnataka-4-to-5-years-290525939809,"Focus on designing, developing, and maintaining Snowflake data environments.Responsible for data modeling, ETL pipelines, and query optimization to ensure efficient and secure data processing.",290525939809,"snowflake,etl pipelines,query optimization,data modeling,etl,rest,python,scala"
Snowflake,Data Engineer - Snowflake,Prudent Globaltech Solutions,1-3 Yrs,Not disclosed,Hyderabad,/job-listings-data-engineer-snowflake-prudent-globaltech-solutions-private-limited-hyderabad-1-to-3-years-270525502028,"A positive attitude and excellent teamwork skills are essential. Key Responsibilities: . Data Pipeline Development: Design,develop,and maintain scalable data pipelines using Snowflake,DBT,Snaplogic,and ETL toolsThe ideal candidate will have a strong ability to optimize SQL queries and a good working knowledge of Python",270525502028,"Analytical skills,SQL queries,Automation,data manipulation,Postgresql,data governance,Troubleshooting,Analytics"
Snowflake,Snowflake Developer,Royal Cyber,6-10 Yrs,Not disclosed,"Hybrid - Hyderabad, Chennai, Bengaluru",/job-listings-snowflake-developer-royal-cyber-hyderabad-chennai-bengaluru-6-to-10-years-290525019842,"Required Skills and Qualifications: 6 to 8 years of experience in data engineering,data warehousing,or data analytics rolesMinimum 3+ years of hands-on experience with Snowflake (data modeling,performance tuning,schema design,etc.)Solid experience with ETL / ELT tools and frameworksExperience in integrating Snowflake with third-party BI tools and APIs",290525019842,"Snowflake,Snowflake Modeling,Data Warehousing,SQL,Modeling,Data,Development,Warehouse"
Snowflake,Snowflake Data Engineer,Momentive Performance,5-10 Yrs,Not disclosed,Bengaluru,/job-listings-snowflake-data-engineer-momentive-performance-bengaluru-5-to-10-years-280525503136,"Build the infrastructure required for ELT from a wide variety of data sourcesBachelor s degree in Computer Science,Business,Math,Statistics,Engineering or related field or equivalent is requiredExperience in tools ETL like Alteryx / Informatica or similar environments .",280525503136,"Automation,Data management,Data modeling,Analytical,Healthcare,Operations,Analytics,Monitoring"
